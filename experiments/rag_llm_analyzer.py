#!/usr/bin/env python3
"""
RAG-LLM ì°¨ì´ ë¶„ì„ ë° ìë™ í•™ìŠµ ì‹œìŠ¤í…œ
- RAG ê²°ê³¼ì™€ LLM ê²°ê³¼ ë¹„êµ
- ì°¨ì´ê°€ í° ê²½ìš° RAG ë°ì´í„°ì— ì¶”ê°€
- LLM ìƒì„± ë°ì´í„°ë¥¼ ê·œì¹™ìœ¼ë¡œ ë³€í™˜
"""

import os
import sys
import json
import re
from typing import List, Dict, Tuple
from datetime import datetime

# ë°±ì—”ë“œ ì„œë¹„ìŠ¤ ì„í¬íŠ¸
sys.path.append('backend')
from services_advanced_rag import GLOBAL_ADVANCED_RAG
from services_gen import generate_advice

class RAGLLMAnalyzer:
    def __init__(self):
        self.rag = GLOBAL_ADVANCED_RAG
        self.differences = []
        self.new_rules = []
        
    def analyze_differences(self, test_results_file: str = "test_results_100_symptoms.json"):
        """100ê°œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ RAG-LLM ì°¨ì´ ë¶„ì„"""
        print("ğŸ” RAG-LLM ì°¨ì´ ë¶„ì„ ì‹œì‘...")
        
        with open(test_results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        for result in data['results']:
            if result['success']:
                self._analyze_single_result(result)
        
        self._generate_improvements()
    
    def _analyze_single_result(self, result: Dict):
        """ë‹¨ì¼ ê²°ê³¼ ë¶„ì„"""
        symptom = result['symptom']
        rag_search = result['rag_search']
        llm_advice = result['llm_advice']
        rule_advice = result['rule_based_advice']
        
        # RAGì—ì„œ ì°¾ì€ ë¬¸ì„œë“¤
        rag_docs = rag_search.get('top_titles', [])
        
        # LLM ì¡°ì–¸
        llm_text = llm_advice.get('preview', '')
        
        # ê·œì¹™ ê¸°ë°˜ ì¡°ì–¸
        rule_text = rule_advice.get('advice', '')
        
        # ì°¨ì´ì  ë¶„ì„
        if self._has_significant_difference(rag_docs, llm_text, rule_text):
            difference = {
                'symptom': symptom,
                'rag_docs': rag_docs,
                'llm_advice': llm_text,
                'rule_advice': rule_text,
                'difference_type': self._classify_difference(rag_docs, llm_text, rule_text),
                'timestamp': datetime.now().isoformat()
            }
            self.differences.append(difference)
    
    def _has_significant_difference(self, rag_docs: List[str], llm_text: str, rule_text: str) -> bool:
        """ì¤‘ìš”í•œ ì°¨ì´ê°€ ìˆëŠ”ì§€ íŒë‹¨"""
        # 1. RAG ë¬¸ì„œê°€ ë¶€ì¡±í•œ ê²½ìš°
        if len(rag_docs) < 2:
            return True
        
        # 2. LLMì´ ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²½ìš°
        if len(llm_text) > len(rule_text) * 1.5:
            return True
        
        # 3. LLMì´ ì¼ë³¸ì–´ ì œí’ˆëª…ì„ í¬í•¨í•˜ëŠ” ê²½ìš°
        japanese_products = re.findall(r'[ã‚¢-ãƒ³]+', llm_text)
        if japanese_products and not any(product in rule_text for product in japanese_products):
            return True
        
        # 4. LLMì´ êµ¬ì²´ì ì¸ ìš©ë²•ì„ ì„¤ëª…í•˜ëŠ” ê²½ìš°
        usage_keywords = ['ë³µìš©', 'ìš©ë²•', 'í•˜ë£¨', 'íšŒ', 'mg', 'ì •', 'ì•Œì•½']
        if any(keyword in llm_text for keyword in usage_keywords) and not any(keyword in rule_text for keyword in usage_keywords):
            return True
        
        return False
    
    def _classify_difference(self, rag_docs: List[str], llm_text: str, rule_text: str) -> str:
        """ì°¨ì´ ìœ í˜• ë¶„ë¥˜"""
        if len(rag_docs) < 2:
            return "RAG_DOCS_INSUFFICIENT"
        elif len(llm_text) > len(rule_text) * 1.5:
            return "LLM_MORE_DETAILED"
        elif re.search(r'[ã‚¢-ãƒ³]+', llm_text):
            return "LLM_HAS_JAPANESE_PRODUCTS"
        else:
            return "LLM_HAS_USAGE_INFO"
    
    def _generate_improvements(self):
        """ê°œì„ ì‚¬í•­ ìƒì„±"""
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼: {len(self.differences)}ê°œ ì°¨ì´ì  ë°œê²¬")
        
        # 1. RAG ë°ì´í„° ì¶”ê°€ ëŒ€ìƒ
        rag_candidates = [d for d in self.differences if d['difference_type'] == 'RAG_DOCS_INSUFFICIENT']
        print(f"ğŸ“š RAG ë°ì´í„° ì¶”ê°€ ëŒ€ìƒ: {len(rag_candidates)}ê°œ")
        
        # 2. ê·œì¹™ ì¶”ê°€ ëŒ€ìƒ
        rule_candidates = [d for d in self.differences if d['difference_type'] in ['LLM_MORE_DETAILED', 'LLM_HAS_JAPANESE_PRODUCTS', 'LLM_HAS_USAGE_INFO']]
        print(f"ğŸ“‹ ê·œì¹™ ì¶”ê°€ ëŒ€ìƒ: {len(rule_candidates)}ê°œ")
        
        # 3. ê°œì„ ì‚¬í•­ ìƒì„±
        self._create_rag_improvements(rag_candidates)
        self._create_rule_improvements(rule_candidates)
    
    def _create_rag_improvements(self, candidates: List[Dict]):
        """RAG ê°œì„ ì‚¬í•­ ìƒì„±"""
        print("\nğŸ”§ RAG ê°œì„ ì‚¬í•­ ìƒì„± ì¤‘...")
        
        for candidate in candidates[:10]:  # ìƒìœ„ 10ê°œë§Œ
            symptom = candidate['symptom']
            llm_advice = candidate['llm_advice']
            
            # LLM ì¡°ì–¸ì„ RAG ë¬¸ì„œë¡œ ë³€í™˜
            rag_doc = self._convert_llm_to_rag_doc(symptom, llm_advice)
            if rag_doc:
                self._save_rag_doc(rag_doc, symptom)
    
    def _create_rule_improvements(self, candidates: List[Dict]):
        """ê·œì¹™ ê°œì„ ì‚¬í•­ ìƒì„±"""
        print("\nğŸ”§ ê·œì¹™ ê°œì„ ì‚¬í•­ ìƒì„± ì¤‘...")
        
        for candidate in candidates[:10]:  # ìƒìœ„ 10ê°œë§Œ
            symptom = candidate['symptom']
            llm_advice = candidate['llm_advice']
            
            # LLM ì¡°ì–¸ì„ ê·œì¹™ìœ¼ë¡œ ë³€í™˜
            new_rule = self._convert_llm_to_rule(symptom, llm_advice)
            if new_rule:
                self.new_rules.append(new_rule)
    
    def _convert_llm_to_rag_doc(self, symptom: str, llm_advice: str) -> str:
        """LLM ì¡°ì–¸ì„ RAG ë¬¸ì„œë¡œ ë³€í™˜"""
        # ì¦ìƒë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(symptom)
        
        # ë¬¸ì„œ êµ¬ì¡°í™”
        doc = f"""
ì¦ìƒ: {symptom}
í‚¤ì›Œë“œ: {', '.join(keywords)}

ìƒì„¸ ì¡°ì–¸:
{llm_advice}

ì¶œì²˜: AI ìƒì„± (LLM ê¸°ë°˜)
ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d')}
"""
        return doc.strip()
    
    def _convert_llm_to_rule(self, symptom: str, llm_advice: str) -> Dict:
        """LLM ì¡°ì–¸ì„ ê·œì¹™ìœ¼ë¡œ ë³€í™˜"""
        # ì¦ìƒ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(symptom)
        
        # OTC ì•½ë¬¼ ì¶”ì¶œ
        otc_products = self._extract_otc_products(llm_advice)
        
        # ì¡°ì–¸ ì¶”ì¶œ
        advice = self._extract_advice(llm_advice)
        
        return {
            'keywords': keywords,
            'advice': advice,
            'otc': otc_products,
            'symptom': symptom
        }
    
    def _extract_keywords(self, symptom: str) -> List[str]:
        """ì¦ìƒì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê¸°ë³¸ í‚¤ì›Œë“œ
        keywords = [symptom]
        
        # ì–¸ì–´ë³„ í‚¤ì›Œë“œ ì¶”ê°€
        if any(char in symptom for char in 'ê°€-í£'):
            keywords.extend(['í•œêµ­ì–´', 'ì¦ìƒ'])
        if any(char in symptom for char in 'a-zA-Z'):
            keywords.extend(['ì˜ì–´', 'symptom'])
        if any(char in symptom for char in 'ã‚¢-ãƒ³'):
            keywords.extend(['ì¼ë³¸ì–´', 'ç—‡çŠ¶'])
        
        return keywords
    
    def _extract_otc_products(self, llm_advice: str) -> List[str]:
        """LLM ì¡°ì–¸ì—ì„œ OTC ì œí’ˆ ì¶”ì¶œ"""
        products = []
        
        # ì¼ë³¸ì–´ ì œí’ˆëª… ì¶”ì¶œ
        japanese_products = re.findall(r'[ã‚¢-ãƒ³]+', llm_advice)
        products.extend(japanese_products)
        
        # í•œêµ­ì–´ ì œí’ˆëª… ì¶”ì¶œ
        korean_products = re.findall(r'[ê°€-í£]+(?:ì œ|ì•½|ì•¡|ì—°ê³ |í¬ë¦¼)', llm_advice)
        products.extend(korean_products)
        
        return list(set(products))
    
    def _extract_advice(self, llm_advice: str) -> str:
        """LLM ì¡°ì–¸ì—ì„œ í•µì‹¬ ì¡°ì–¸ ì¶”ì¶œ"""
        # ì²« ë²ˆì§¸ ë¬¸ì¥ì„ í•µì‹¬ ì¡°ì–¸ìœ¼ë¡œ ì‚¬ìš©
        sentences = llm_advice.split('.')
        if sentences:
            return sentences[0].strip() + '.'
        return llm_advice[:100] + '...'
    
    def _save_rag_doc(self, doc: str, symptom: str):
        """RAG ë¬¸ì„œ ì €ì¥"""
        # íŒŒì¼ëª… ìƒì„±
        safe_symptom = re.sub(r'[^\w\s-]', '', symptom).strip()
        filename = f"data/passages/jp/llm_generated_{safe_symptom[:20]}.txt"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        # íŒŒì¼ ì €ì¥
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(doc)
        
        print(f"  ğŸ’¾ RAG ë¬¸ì„œ ì €ì¥: {filename}")
    
    def save_improvements(self):
        """ê°œì„ ì‚¬í•­ ì €ì¥"""
        # 1. ì°¨ì´ì  ë¶„ì„ ê²°ê³¼ ì €ì¥
        with open("rag_llm_differences.json", "w", encoding="utf-8") as f:
            json.dump(self.differences, f, ensure_ascii=False, indent=2)
        
        # 2. ìƒˆë¡œìš´ ê·œì¹™ ì €ì¥
        with open("new_rules.json", "w", encoding="utf-8") as f:
            json.dump(self.new_rules, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ê°œì„ ì‚¬í•­ ì €ì¥ ì™„ë£Œ:")
        print(f"  - RAG-LLM ì°¨ì´ì : rag_llm_differences.json")
        print(f"  - ìƒˆë¡œìš´ ê·œì¹™: new_rules.json")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§  RAG-LLM ì°¨ì´ ë¶„ì„ ë° ìë™ í•™ìŠµ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    analyzer = RAGLLMAnalyzer()
    analyzer.analyze_differences()
    analyzer.save_improvements()
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
