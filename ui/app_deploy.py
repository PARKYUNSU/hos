import os
import streamlit as st
from streamlit_geolocation import streamlit_geolocation
import requests
import pathlib
import re
from typing import List, Tuple, Dict, Optional
from rank_bm25 import BM25Okapi
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from PIL import Image
import numpy as np
import base64
import json
import time
import sys
from datetime import datetime

# ë°±ì—”ë“œ ì„œë¹„ìŠ¤ ì„í¬íŠ¸ (ë°°í¬ìš© - ë¡œê¹… ì œì™¸)
sys.path.append('backend')
# from services_logging import symptom_logger
# from services_auto_crawler import auto_crawl_unhandled_symptoms
from services_advanced_rag import GLOBAL_ADVANCED_RAG, load_disk_passages
from services_gen import generate_advice

st.set_page_config(page_title="ì‘ê¸‰ ì±—ë´‡", page_icon="ğŸš‘", layout="centered")
st.title("ì‘ê¸‰ í™˜ì ì±—ë´‡ (ì¼ë³¸)")
st.caption("ì¼ë³¸ ì—¬í–‰ìë¥¼ ìœ„í•œ ì‘ê¸‰ ì˜ë£Œ ì¡°ì–¸ - VLM/LLM/RAG í†µí•©")

# ==================== RAG ì‹œìŠ¤í…œ (ê³ ë„í™”ëœ ì‹œìŠ¤í…œ ì‚¬ìš©) ====================
# ê¸°ì¡´ HybridRAG í´ë˜ìŠ¤ëŠ” services_advanced_rag.pyë¡œ ì´ë™
# ì—¬ê¸°ì„œëŠ” ê³ ë„í™”ëœ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©

# ==================== ì§€ì˜¤ ì„œë¹„ìŠ¤ ====================
NOMINATIM_URL = "https://nominatim.openstreetmap.org/search"
OVERPASS_URLS = [
    "https://overpass-api.de/api/interpreter",
    "https://lz4.overpass-api.de/api/interpreter",
    "https://overpass.kumi.systems/api/interpreter",
]
REVERSE_URL = "https://nominatim.openstreetmap.org/reverse"

def _headers() -> Dict[str, str]:
    try:
        contact = st.secrets.get("CONTACT_EMAIL", "hos-emergency-bot/0.1")
    except:
        contact = os.getenv("CONTACT_EMAIL", "hos-emergency-bot/0.1")
    return {"User-Agent": f"hos-emergency-bot/0.1 ({contact})"}

def geocode_place(place: str) -> Optional[Dict[str, float]]:
    if not place:
        return None
    QUICK: Dict[str, Tuple[float, float]] = {
        "shibuya": (35.661777, 139.704051),
        "tokyo": (35.676203, 139.650311),
        "japan": (36.204824, 138.252924),
    }
    key = (place or "").strip().lower()
    if key in QUICK:
        lat, lon = QUICK[key]
        return {"lat": lat, "lon": lon}
    params = {
        "q": place,
        "format": "json",
        "limit": 1,
        "addressdetails": 0,
    }
    try:
        r = requests.get(NOMINATIM_URL, params=params, headers=_headers(), timeout=6)
        if not r.ok:
            return None
        arr = r.json()
        if not arr:
            return None
        lat = float(arr[0]["lat"])
        lon = float(arr[0]["lon"])
        return {"lat": lat, "lon": lon}
    except Exception:
        return QUICK.get("tokyo") and {"lat": QUICK["tokyo"][0], "lon": QUICK["tokyo"][1]}

def reverse_geocode(lat: float, lon: float) -> str:
    try:
        params = {"format": "json", "lat": lat, "lon": lon, "zoom": 18, "addressdetails": 1}
        r = requests.get(REVERSE_URL, params=params, headers=_headers(), timeout=6)
        if not r.ok:
            return ""
        data = r.json()
        address = data.get("display_name") or ""
        return address or ""
    except Exception:
        return ""

def build_address_from_tags(tags: Dict[str, str]) -> str:
    parts: List[str] = []
    # Common OSM address tags in Japan
    for key in [
        "addr:prefecture",
        "addr:city", 
        "addr:ward",
        "addr:district",
        "addr:suburb",
        "addr:neighbourhood",
        "addr:street",
        "addr:block",
        "addr:housenumber",
        "addr:postcode",
    ]:
        val = tags.get(key)
        if val:
            parts.append(val)
    if not parts:
        # fallback single fields
        for key in ["addr:full", "addr:place", "addr:hamlet"]:
            val = tags.get(key)
            if val:
                parts.append(val)
                break
    return " ".join(parts)

def random_tokyo_latlon() -> tuple[float, float]:
    """ë„ì¿„ì˜ ëœë¤í•œ ì§€ì—­ ì¢Œí‘œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    import random
    
    # ë„ì¿„ ì£¼ìš” ì§€ì—­ë“¤ì˜ ëŒ€í‘œ ì¢Œí‘œ
    tokyo_areas = [
        (35.676203, 139.650311),  # ì‹ ì£¼ì¿ 
        (35.658581, 139.745433),  # ì‹œë¶€ì•¼
        (35.676191, 139.650310),  # í•˜ë¼ì£¼ì¿ 
        (35.658034, 139.701636),  # ë¡¯í°ê¸°
        (35.676191, 139.650310),  # ê¸´ì
        (35.658581, 139.745433),  # ì•„í‚¤í•˜ë°”ë¼
        (35.676191, 139.650310),  # ìš°ì—ë…¸
        (35.658034, 139.701636),  # ì•„ì‚¬ì¿ ì‚¬
        (35.676191, 139.650310),  # ì´ì¼€ë¶€ì¿ ë¡œ
        (35.658581, 139.745433),  # ì‹ ë°”ì‹œ
    ]
    
    # ëœë¤í•˜ê²Œ ì„ íƒëœ ì§€ì—­ì— ì•½ê°„ì˜ ëœë¤ ì˜¤í”„ì…‹ ì¶”ê°€
    base_lat, base_lon = random.choice(tokyo_areas)
    
    # Â±0.01ë„ ë²”ìœ„ ë‚´ì—ì„œ ëœë¤ ì˜¤í”„ì…‹ (ì•½ Â±1km)
    lat_offset = random.uniform(-0.01, 0.01)
    lon_offset = random.uniform(-0.01, 0.01)
    
    return (base_lat + lat_offset, base_lon + lon_offset)

def search_hospitals(lat: float, lon: float, radius_m: int = 2000) -> List[Dict]:
    query = f"""
    [out:json][timeout:6];
    (
      node["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
      way["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
      relation["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
    );
    out center 20;
    """
    r = None
    for endpoint in OVERPASS_URLS:
        try:
            r = requests.post(endpoint, data={"data": query}, timeout=7)
            if r.ok:
                break
        except Exception:
            r = None
            continue
    if r is None:
        return []
    results: List[Dict] = []
    if r.ok:
        data = r.json()
        for el in data.get("elements", [])[:20]:
            tags = el.get("tags", {})
            name = tags.get("name") or tags.get("name:en") or tags.get("name:ja") or "Unknown"
            lat_out = el.get("lat") or (el.get("center") or {}).get("lat")
            lon_out = el.get("lon") or (el.get("center") or {}).get("lon")
            
            # ì£¼ì†Œ ì •ë³´ êµ¬ì„±
            addr = build_address_from_tags(tags)
            if not addr and lat_out and lon_out:
                addr = reverse_geocode(lat_out, lon_out)
            
            results.append({
                "name": name,
                "address": addr or f"ìœ„ë„: {lat_out:.4f}, ê²½ë„: {lon_out:.4f}",
                "lat": lat_out,
                "lon": lon_out,
            })
    return results

def search_pharmacies(lat: float, lon: float, radius_m: int = 1500) -> List[Dict]:
    query = f"""
    [out:json][timeout:7];
    (
      node["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
      way["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
      relation["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
    );
    out center 30;
    """
    r = None
    for endpoint in OVERPASS_URLS:
        try:
            r = requests.post(endpoint, data={"data": query}, timeout=7)
            if r.ok:
                break
        except Exception:
            r = None
            continue
    if r is None:
        return []
    results: List[Dict] = []
    if r.ok:
        data = r.json()
        for el in data.get("elements", [])[:30]:
            tags = el.get("tags", {})
            name = tags.get("name") or tags.get("name:en") or tags.get("name:ja") or "Unknown"
            lat_out = el.get("lat") or (el.get("center") or {}).get("lat")
            lon_out = el.get("lon") or (el.get("center") or {}).get("lon")
            
            # ì£¼ì†Œ ì •ë³´ êµ¬ì„±
            addr = build_address_from_tags(tags)
            if not addr and lat_out and lon_out:
                addr = reverse_geocode(lat_out, lon_out)
            
            results.append({
                "name": name,
                "address": addr or f"ìœ„ë„: {lat_out:.4f}, ê²½ë„: {lon_out:.4f}",
                "lat": lat_out,
                "lon": lon_out,
            })
    return results

# ==================== ê¸°ë³¸ ê·œì¹™ ====================
def simple_text_rules(symptoms_text: str) -> dict:
    t = (symptoms_text or "").lower()
    advice = "ì¦ìƒì— ëŒ€í•œ ê¸°ë³¸ ì‘ê¸‰ì²˜ì¹˜ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤. ì‹¬ê°í•œ ì¦ìƒì´ë©´ ì¦‰ì‹œ 119(ì¼ë³¸: 119)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”."
    otc: list = []
    
    if any(k in t for k in ["fever", "ì—´", "ç™ºç†±"]):
        otc.append("í•´ì—´ì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)")
    if any(k in t for k in ["cough", "ê¸°ì¹¨", "å’³"]):
        otc.append("ì§„í•´ê±°ë‹´ì œ")
    if any(k in t for k in ["diarrhea", "ì„¤ì‚¬", "ä¸‹ç—¢"]):
        otc.append("ì§€ì‚¬ì œ ë° ìˆ˜ë¶„ë³´ì¶©")
    if any(k in t for k in ["abdominal pain", "stomach ache", "ë°°ì•„í””", "ë³µí†µ", "è…¹ç—›"]):
        otc.extend(["ì œì‚°ì œ/ìœ„ì‚°ì–µì œì œ(ì¦ìƒì— ë”°ë¼)", "ê°€ìŠ¤ì™„í™”ì œ(ì‹œë©”í‹°ì½˜)", "ì§„í†µì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)"])
    if any(k in t for k in ["headache", "ë‘í†µ", "é ­ç—›"]):
        if "í•´ì—´ì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)" not in otc:
            otc.append("ì§„í†µì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)")
    if any(k in t for k in ["vomit", "vomiting", "êµ¬í† ", "å˜”å", "íƒˆìˆ˜", "dehydration"]):
        otc.append("ê²½êµ¬ìˆ˜ë¶„ë³´ì¶©ì•¡(ORS)")
    if any(k in t for k in ["rash", "ë°œì§„", "ì•Œë ˆë¥´ê¸°", "è•éº»ç–¹", "ã˜ã‚“ã¾ã—ã‚“", "allergy"]):
        otc.append("í•­íˆìŠ¤íƒ€ë¯¼ì œ")
    if any(k in t for k in ["sore throat", "ì¸í›„í†µ", "ëª©ì•„í””", "å–‰ã®ç—›ã¿"]):
        otc.append("ëª©ì—¼ì¦ ì™„í™” ëª©ìº”ë””/ë¡œì  ì§€")
    if any(k in t for k in ["stuffy nose", "nasal congestion", "ì½”ë§‰í˜", "é¼»ã¥ã¾ã‚Š"]):
        otc.append("ë¹„ì¶©í˜ˆ ì œê±°ì œ(ë””ì½˜ì œìŠ¤í„´íŠ¸)")
    if any(k in t for k in ["toothache", "ì¹˜í†µ", "æ­¯ç—›"]):
        if "ì§„í†µì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)" not in otc:
            otc.append("ì§„í†µì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)")
    if any(k in t for k in ["cut", "bleeding", "ìƒì²˜", "å‡ºè¡€"]):
        advice = "ìƒì²˜ ë¶€ìœ„ë¥¼ ì••ë°•í•˜ì—¬ ì§€í˜ˆí•˜ê³ , ê¹¨ë—í•œ ë¬¼ë¡œ ì„¸ì²™ í›„ ë©¸ê·  ê±°ì¦ˆë¥¼ ì ìš©í•˜ì„¸ìš”. ì‹¬í•œ ì¶œí˜ˆì€ ì¦‰ì‹œ 119."
    
    # ë²Œë ˆ ë¬¼ë¦¼ (ë§ë²Œ/ë²Œ í‚¤ì›Œë“œ ì œì™¸)
    if any(k in t for k in ["ë²Œë ˆ", "ë¬¼ë¦¼", "ë²Œë ˆì— ë¬¼ë¦¼", "ë²Œë ˆì—ë¬¼ë¦¼", "ëª¨ê¸°", "ëª¨ê¸°ì— ë¬¼ë¦¼", "ëª¨ê¸°ì—ë¬¼ë¦¼", "insect bite", "è™«ã«åˆºã•ã‚ŒãŸ"]) and not any(k in t for k in ["ë§ë²Œ", "ë²Œ", "ì˜ì„", "wasp", "bee", "èœ‚"]):
        advice = "ë²Œë ˆ ë¬¼ë¦¼: ì¦‰ì‹œ í•´ë‹¹ ë¶€ìœ„ë¥¼ ê¹¨ë—í•œ ë¬¼ë¡œ ì”»ê³ , ì–¼ìŒì°œì§ˆë¡œ ë¶€ì¢…ì„ ì™„í™”í•˜ì„¸ìš”. í•­íˆìŠ¤íƒ€ë¯¼ ì—°ê³ ë¥¼ ë°”ë¥´ê³ , ê¸ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”. 24ì‹œê°„ í›„ì—ë„ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì˜ë£Œì§„ ìƒë‹´í•˜ì„¸ìš”."
        otc.extend(["í•­íˆìŠ¤íƒ€ë¯¼ ì—°ê³ ", "ì†Œë…ì œ", "ì–¼ìŒíŒ©"])
    
    # ë§ë²Œ ì˜ì„ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    elif any(k in t for k in ["ë§ë²Œ", "ë²Œ", "ì˜ì„", "ë§ë²Œì— ì˜ì„", "ë§ë²Œì—ì˜ì„", "ë²Œì— ì˜ì„", "ë²Œì—ì˜ì„", "wasp sting", "bee sting", "èœ‚ã«åˆºã•ã‚ŒãŸ"]):
        advice = "ë§ë²Œ ì˜ì„: ì¦‰ì‹œ ì¹¨ì„ ì œê±°í•˜ê³ , ê¹¨ë—í•œ ë¬¼ë¡œ ì„¸ì²™í•˜ì„¸ìš”. ì–¼ìŒì°œì§ˆë¡œ ë¶€ì¢…ì„ ì™„í™”í•˜ê³ , ìƒì²˜ ë¶€ìœ„ë¥¼ ì‹¬ì¥ë³´ë‹¤ ë†’ê²Œ ìœ ì§€í•˜ì„¸ìš”. í˜¸í¡ê³¤ë€, ì „ì‹  ë‘ë“œëŸ¬ê¸°, ì˜ì‹ ë³€í™” ì‹œ ì¦‰ì‹œ 119ì— ì—°ë½í•˜ì„¸ìš”."
        otc.extend(["í•­íˆìŠ¤íƒ€ë¯¼ ì—°ê³ ", "í•­íˆìŠ¤íƒ€ë¯¼ì œ(ê²½êµ¬)", "ì†Œë…ì œ", "ì–¼ìŒíŒ©"])
    
    # LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ ì¡°ì–¸ ìƒì„± (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
    try:
        # RAG ê²€ìƒ‰ ê²°ê³¼ ì¤€ë¹„
        rag_passages = []
        if 'hits' in locals() and hits:
            rag_passages = [hit[0] for hit in hits[:3]]  # ìƒìœ„ 3ê°œ ë¬¸ì„œ

        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì¤€ë¹„ (ê°„ë‹¨í•œ ë²„ì „)
        image_findings = []
        if 'uploaded_file' in locals() and uploaded_file:
            image_findings = ["ì´ë¯¸ì§€ ë¶„ì„ë¨"] # Placeholder, actual image analysis is in main.py

        # LLM ì¡°ì–¸ ìƒì„±
        if rag_passages or image_findings:
            llm_advice = generate_advice(symptoms_text, image_findings, rag_passages)
            if llm_advice and not llm_advice.startswith("ì¦ìƒì— ëŒ€í•œ ì¼ë°˜ ì¡°ì–¸ì…ë‹ˆë‹¤"):
                advice = llm_advice
    except Exception as e:
        # LLM ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì¡°ì–¸ ì‚¬ìš©
        pass

    
    # ==================== LLM ê¸°ë°˜ ìë™ ìƒì„± ê·œì¹™ ====================

    # ì—´ì´ 39ë„ì…ë‹ˆë‹¤ ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ì—´ì´ 39ë„ì…ë‹ˆë‹¤"]):
        advice = "ì—´ì´ 39ë„ì¸ ê²½ìš°, ì—¬ëŸ¬ ì›ì¸ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, íŠ¹íˆ ê°ì—¼ì´ë‚˜ ì—¼ì¦ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        otc.extend(['í•´ì—´ì œ'])

    # fever 38.5 ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["fever 38.5"]):
        advice = "ì¦ìƒìœ¼ë¡œ 38."
        otc.extend(['í•´ì—´ì œ', 'ì˜ì•½'])

    # ç™ºç†±ãŒç¶šãã¾ã™ ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ç™ºç†±ãŒç¶šãã¾ã™"]):
        advice = "ë°œì—´ì´ ì§€ì†ë˜ëŠ” ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì¹˜ë¥¼ ì·¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        otc.extend([])

    # ê³ ì—´ì´ ë‚˜ìš” ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ê³ ì—´ì´ ë‚˜ìš”"]):
        advice = "ê³ ì—´ì´ ë‚˜ëŠ” ì¦ìƒì— ëŒ€í•´ ì•ˆì „ ì¤‘ì‹¬ì˜ ì‘ê¸‰ì²˜ì¹˜ ë° OTC ì¡°ì–¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        otc.extend([])

    # ì²´ì˜¨ì´ ë†’ì•„ìš” ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ì²´ì˜¨ì´ ë†’ì•„ìš”"]):
        advice = "ì²´ì˜¨ì´ ë†’ë‹¤ëŠ” ê²ƒì€ ë°œì—´ì„ ì˜ë¯¸í•˜ë©°, ì´ëŠ” ì—¬ëŸ¬ ì›ì¸ì— ì˜í•´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        otc.extend(['ì˜ì•½'])

    # ì—´ê°ì´ ìˆì–´ìš” ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ì—´ê°ì´ ìˆì–´ìš”"]):
        advice = "ì—´ê°ì´ ìˆëŠ” ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì¹˜ë¥¼ ì·¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        otc.extend(['ì˜ì•½'])

    # ëª¸ì´ ëœ¨ê±°ì›Œìš” ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ëª¸ì´ ëœ¨ê±°ì›Œìš”"]):
        advice = "ëª¸ì´ ëœ¨ê±°ìš´ ì¦ìƒì€ ì—¬ëŸ¬ ì›ì¸ì— ì˜í•´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë©°, íŠ¹íˆ ì—´ì´ ë‚˜ëŠ” ê²½ìš°ì—ëŠ” ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        otc.extend(['ì˜ì•½'])

    # ë°œì—´ê³¼ ë‘í†µ ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ë°œì—´ê³¼ ë‘í†µ"]):
        advice = "ë°œì—´ê³¼ ë‘í†µ ì¦ìƒì— ëŒ€í•´ ì•ˆì „ ì¤‘ì‹¬ì˜ ì‘ê¸‰ì²˜ì¹˜ ë° OTC ì¡°ì–¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        otc.extend(['í•´ì—´ì œ', 'ì˜ì•½'])

    # ê³ ì—´ê³¼ ì˜¤í•œ ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ê³ ì—´ê³¼ ì˜¤í•œ"]):
        advice = "ê³ ì—´ê³¼ ì˜¤í•œ ì¦ìƒì— ëŒ€í•œ ì•ˆì „ ì¤‘ì‹¬ì˜ ì‘ê¸‰ì²˜ì¹˜ ë° OTC ì¡°ì–¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        otc.extend([])

    # ì—´ì´ ì•ˆ ë–¨ì–´ì ¸ìš” ê´€ë ¨ ê·œì¹™
    if any(k in t for k in ["ì—´ì´ ì•ˆ ë–¨ì–´ì ¸ìš”"]):
        advice = "ì—´ì´ ë–¨ì–´ì§€ì§€ ì•ŠëŠ” ì¦ìƒì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ ì•ˆì „ ì¤‘ì‹¬ì˜ ì‘ê¸‰ì²˜ì¹˜ ë° OTC ì¡°ì–¸ì„ ë“œë¦½ë‹ˆë‹¤."
        otc.extend([])

    return {"advice": advice, "otc": otc}

# ==================== ì‘ê¸‰ìƒí™© ê°ì§€ ====================
CRITICAL_KEYWORDS = [
    "chest pain", "ì‹¬í•œ ê°€ìŠ´ í†µì¦", "èƒ¸ã®æ¿€ç—›",
    "severe bleeding", "ëŒ€ëŸ‰ ì¶œí˜ˆ", "å¤§é‡å‡ºè¡€",
    "unconscious", "ì˜ì‹ ì—†ìŒ", "æ„è­˜ãªã—",
    "stroke", "í¸ë§ˆë¹„", "è„³å’ä¸­",
    "difficulty breathing", "ìˆ¨ì´ ê°€ì¨", "å‘¼å¸å›°é›£",
    "severe abdominal pain", "ë³µë¶€ ê·¹ì‹¬í•œ í†µì¦", "æ¿€ã—ã„è…¹ç—›",
    "anaphylaxis", "ì•„ë‚˜í•„ë½ì‹œìŠ¤", "ì‹¬í•œ ì•Œë ˆë¥´ê¸° ë°˜ì‘", "ì „ì‹  ë‘ë“œëŸ¬ê¸°", "í˜¸í¡ê³¤ë€",
    "severe allergic reaction", "å…¨èº«è•éº»ç–¹", "å‘¼å¸å›°é›£",
]

def detect_emergency(symptoms_text: str) -> list:
    t = (symptoms_text or "").lower()
    reasons: list = []
    for k in CRITICAL_KEYWORDS:
        if k in t:
            reasons.append(k)
    return reasons

# ==================== ì´ë¯¸ì§€ ë¶„ì„ ====================
def simple_image_screening(img: Image.Image) -> List[str]:
    w, h = img.size
    findings: List[str] = []
    if min(w, h) < 128:
        findings.append("ì €í•´ìƒë„ ì´ë¯¸ì§€")
    return findings

def detect_emergency_from_image(img: Image.Image, raw_image: bytes = None) -> List[str]:
    reasons: List[str] = []
    red_thr = 0.25
    burn_thr = 0.30
    
    # íœ´ë¦¬ìŠ¤í‹± ë¶„ì„
    try:
        small = img.resize((224, 224))
        hsv = small.convert("HSV")
        arr = np.array(hsv)
        h = arr[:, :, 0].astype(np.float32)
        s = arr[:, :, 1].astype(np.float32)
        v = arr[:, :, 2].astype(np.float32)
        
        red_mask = ((h < 10) | (h > 245)) & (s > 100) & (v > 60)
        red_ratio = float(red_mask.mean())
        if red_ratio > red_thr:
            reasons.append("ì´ë¯¸ì§€ìƒ ê³¼ë‹¤ ì¶œí˜ˆ ì˜ì‹¬")
            
        orange_mask = (h >= 10) & (h <= 50) & (s > 120) & (v > 120)
        orange_ratio = float(orange_mask.mean())
        if orange_ratio > burn_thr:
            reasons.append("ì´ë¯¸ì§€ìƒ í™”ìƒ/ê´‘ë²”ìœ„ í™ë°˜ ì˜ì‹¬")
    except Exception:
        pass
    
    # OpenAI Vision API ë¶„ì„ (í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ëœ ê²½ìš°)
    try:
        api_key = st.secrets.get("OPENAI_API_KEY")
        if api_key and raw_image:
            import openai
            client = openai.OpenAI(api_key=api_key)
            
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            import base64
            from io import BytesIO
            
            img_buffer = BytesIO()
            img.save(img_buffer, format="JPEG")
            img_bytes = img_buffer.getvalue()
            b64_image = base64.b64encode(img_bytes).decode("utf-8")
            
            # ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ í”„ë¡¬í”„íŠ¸
            prompt = """
            ì´ ì˜ë£Œ/ìƒí•´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ í•­ëª©ë“¤ì„ í™•ì¸í•˜ê³  ë°œê²¬ëœ ê²ƒë§Œ í•œêµ­ì–´ë¡œ ë³´ê³ í•´ì£¼ì„¸ìš”:
            
            ì‘ê¸‰ìƒí™©:
            - ì‹¬í•œ ì¶œí˜ˆ (ê³¼ë‹¤ ì¶œí˜ˆ, ëŒ€ëŸ‰ ì¶œí˜ˆ)
            - ì‹¬í•œ í™”ìƒ (2ë„ ì´ìƒ í™”ìƒ, ê´‘ë²”ìœ„ í™”ìƒ)
            - ë¼ˆ ë…¸ì¶œ (ê³¨ì ˆ, ê°œë°©ì„± ê³¨ì ˆ)
            - ì ˆë‹¨ìƒ (ì†ê°€ë½, íŒ”, ë‹¤ë¦¬ ì ˆë‹¨)
            - ì¤‘ì¦ ì™¸ìƒ (ì‹¬ê°í•œ ìƒì²˜, ê¹Šì€ ìƒì²˜)
            
            ì¼ë°˜ ì˜ë£Œìƒí™©:
            - ë°œì§„, ì•Œë ˆë¥´ê¸° ë°˜ì‘
            - ë¶€ì¢…, ë¶“ê¸°
            - ë©, íƒ€ë°•ìƒ
            - ê°€ë²¼ìš´ ìƒì²˜, ì°°ê³¼ìƒ
            - í”¼ë¶€ì—¼, ìŠµì§„
            - ë¬¼ì§‘, ìˆ˜í¬
            
            ë°œê²¬ëœ ì¦ìƒì´ ì—†ìœ¼ë©´ "ì •ìƒ"ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.
            """
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{b64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500,
                temperature=0.1
            )
            
            analysis = response.choices[0].message.content.strip()
            
            # ì‘ê¸‰ìƒí™© í‚¤ì›Œë“œ ì²´í¬
            emergency_keywords = ["ì‹¬í•œ ì¶œí˜ˆ", "ê³¼ë‹¤ ì¶œí˜ˆ", "ëŒ€ëŸ‰ ì¶œí˜ˆ", "ì‹¬í•œ í™”ìƒ", "2ë„ ì´ìƒ", "ê´‘ë²”ìœ„ í™”ìƒ", 
                                "ë¼ˆ ë…¸ì¶œ", "ê³¨ì ˆ", "ê°œë°©ì„±", "ì ˆë‹¨", "ì¤‘ì¦ ì™¸ìƒ", "ì‹¬ê°í•œ ìƒì²˜", "ê¹Šì€ ìƒì²˜"]
            
            for keyword in emergency_keywords:
                if keyword in analysis:
                    reasons.append(f"AI ë¶„ì„: {analysis}")
                    break
            else:
                # ì‘ê¸‰ìƒí™©ì´ ì•„ë‹Œ ê²½ìš° ì¼ë°˜ ì˜ë£Œìƒí™©ìœ¼ë¡œ ë¶„ë¥˜
                if "ì •ìƒ" not in analysis and analysis:
                    reasons.append(f"AI ë¶„ì„: {analysis}")
                    
    except Exception as e:
        # OpenAI API ì˜¤ë¥˜ ì‹œ íœ´ë¦¬ìŠ¤í‹± ê²°ê³¼ë§Œ ì‚¬ìš©
        pass
    
    return reasons

# ==================== ì¼ë³¸ì–´ ë¬¸ì¥ ìƒì„± ====================
def build_jp_phrase(symptoms_text: str, otc: list) -> str:
    base = "è–¬å±€ã§ç›¸è«‡ã—ãŸã„ã§ã™ã€‚"
    if any("ì§€ì‚¬ì œ" in o or "ì„¤ì‚¬" in symptoms_text for o in otc) or ("ì„¤ì‚¬" in (symptoms_text or "")):
        return base + "ã€è…¹ç—›ã‚„ä¸‹ç—¢ãŒã‚ã‚Šã¾ã™ã€‚å¸‚è²©ã®æ•´è…¸å‰¤ã‚„ä¸‹ç—¢æ­¢ã‚ã‚’æ¢ã—ã¦ã„ã¾ã™ã€‚ã€"
    if any("í•´ì—´" in o or "ì—´" in symptoms_text for o in otc) or ("ë°œì—´" in (symptoms_text or "") or "ì—´" in (symptoms_text or "")):
        return base + "ã€ç™ºç†±ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚»ãƒˆã‚¢ãƒŸãƒãƒ•ã‚§ãƒ³æˆåˆ†ã®è§£ç†±è–¬ã‚’æ¢ã—ã¦ã„ã¾ã™ã€‚ã€"
    if any("ì§„í•´" in o or "ê¸°ì¹¨" in symptoms_text for o in otc) or ("å’³" in (symptoms_text or "")):
        return base + "ã€å’³ãŒã‚ã‚Šã¾ã™ã€‚å¸‚è²©ã®é®å’³å»ç—°è–¬ã‚’æ¢ã—ã¦ã„ã¾ã™ã€‚ã€"
    return base + "ã€ç—‡çŠ¶ã«åˆã†ä¸€èˆ¬ç”¨åŒ»è–¬å“ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ã€"

def map_otc_to_brands(otc: list) -> list:
    hints: list = []
    for o in otc:
        lo = o.lower()
        if "í•´ì—´" in o or "acet" in lo:
            hints.append("è§£ç†±è–¬: ã‚¢ã‚»ãƒˆã‚¢ãƒŸãƒãƒ•ã‚§ãƒ³é…åˆè£½å“")
        if "ì§€ì‚¬" in o:
            hints.append("ä¸‹ç—¢æ­¢ã‚/æ•´è…¸å‰¤: ä¹³é…¸èŒ/ãƒ­ãƒšãƒ©ãƒŸãƒ‰ç³»(ç—‡çŠ¶ã«ã‚ˆã‚Š) â€»ç”¨æ³•æ³¨æ„")
        if "ì œì‚°" in o or "ìœ„ì‚°" in o:
            hints.append("èƒƒè–¬: åˆ¶é…¸è–¬/H2ãƒ–ãƒ­ãƒƒã‚«ãƒ¼ç³»(ç—‡çŠ¶ã«ã‚ˆã‚Š) â€»ç›¸äº’ä½œç”¨æ³¨æ„")
        if "ê°€ìŠ¤" in o or "ì‹œë©”í‹°ì½˜" in o:
            hints.append("èƒƒè…¸è–¬: ã‚·ãƒ¡ãƒã‚³ãƒ³é…åˆ")
        if "ì§„í†µì œ" in o:
            hints.append("é®ç—›è–¬: ã‚¢ã‚»ãƒˆã‚¢ãƒŸãƒãƒ•ã‚§ãƒ³å„ªå…ˆ(ã‚¤ãƒ–ãƒ—ãƒ­ãƒ•ã‚§ãƒ³ç­‰ã¯çŠ¶æ³ã§å›é¿)")
        if "ì§„í•´" in o:
            hints.append("å’³æ­¢ã‚: é®å’³å»ç—°è–¬ã‚«ãƒ†ã‚´ãƒª")
        if "í•­íˆìŠ¤íƒ€ë¯¼" in o:
            hints.append("æŠ—ãƒ’ã‚¹ã‚¿ãƒŸãƒ³è–¬: ã‹ã‚†ã¿/è•éº»ç–¹ç­‰")
        if "ê²½êµ¬ìˆ˜ë¶„ë³´ì¶©" in o or "ORS" in o.upper():
            hints.append("çµŒå£è£œæ°´æ¶²(ORS): è„±æ°´æ™‚ã®é›»è§£è³ª/æ°´åˆ†è£œçµ¦")
        if "ë¡œì  ì§€" in o or "ëª©ì—¼ì¦" in o:
            hints.append("ãƒˆãƒ­ãƒ¼ãƒ/ã®ã©é£´: å’½é ­ç—›ç·©å’Œ")
        if "ë¹„ì¶©í˜ˆ" in o or "ë””ì½˜ì œìŠ¤í„´íŠ¸" in o or "decongestant" in lo:
            hints.append("é¼»ã¥ã¾ã‚Š: è¡€ç®¡åç¸®ç‚¹é¼»è–¬(çŸ­æœŸä½¿ç”¨)")
    
    out = []
    for h in hints:
        if h not in out:
            out.append(h)
    return out

# ==================== ì§€ë„ ë§í¬ ìƒì„± ====================
def build_google_maps_link(lat: Optional[float], lon: Optional[float], name: Optional[str] = None) -> Optional[str]:
    if lat is None or lon is None:
        return None
    q = f"{lat},{lon}"
    if name:
        q = name
    return f"https://www.google.com/maps/search/?api=1&query={q}"

# ==================== OTC ì´ë¯¸ì§€ ë§¤í•‘ ====================
def map_otc_to_images(otc: list) -> list:
    urls: list = []
    
    def add_for(cat: str, placeholder: str) -> None:
        # ë¡œì»¬ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í”Œë ˆì´ìŠ¤í™€ë”
        urls.append(placeholder)
    
    for o in otc:
        lo = o.lower()
        if ("í•´ì—´" in o) or ("acet" in lo):
            add_for("acetaminophen", "ğŸ’Š")
        if "ì§€ì‚¬" in o:
            add_for("antidiarrheal", "ğŸ’Š")
        if ("ì œì‚°" in o) or ("ìœ„ì‚°" in o):
            add_for("antacid", "ğŸ’Š")
        if ("ê°€ìŠ¤" in o) or ("ì‹œë©”í‹°ì½˜" in o):
            add_for("simethicone", "ğŸ’Š")
        if "í•­íˆìŠ¤íƒ€ë¯¼" in o:
            add_for("antihistamine", "ğŸ’Š")
        if ("ê²½êµ¬ìˆ˜ë¶„ë³´ì¶©" in o) or ("ors" in lo):
            add_for("ors", "ğŸ’Š")
        if ("ë¡œì  ì§€" in o) or ("ëª©ì—¼ì¦" in o):
            add_for("lozenge", "ğŸ’Š")
        if ("ë¹„ì¶©í˜ˆ" in o) or ("decongestant" in lo) or ("ë””ì½˜ì œìŠ¤í„´íŠ¸" in o):
            add_for("decongestant", "ğŸ’Š")
        if ("í™”ìƒ" in o) or ("burn" in lo):
            add_for("burngel", "ğŸ’Š")
        if ("ë³´ìŠµ" in o) or ("ê±´ì¡°" in o) or ("atopy" in lo) or ("ì•„í† í”¼" in o):
            add_for("emollient", "ğŸ’Š")
    
    # ì¤‘ë³µ ì œê±°
    dedup: list = []
    for u in urls:
        if u not in dedup:
            dedup.append(u)
    return dedup

# ==================== RAD-AR ì˜ì•½í’ˆ ê²€ìƒ‰ ====================
import re
import time
from urllib.parse import urljoin, quote
from bs4 import BeautifulSoup
import json
from pathlib import Path

RADAR_BASE = "https://www.rad-ar.or.jp/siori/english/"
RADAR_SEARCH_URL = urljoin(RADAR_BASE, "search")

RADAR_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
    "Accept-Language": "en,ja;q=0.9,ko;q=0.8",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Referer": RADAR_BASE.rstrip("/") + "/",
}

def radar_session():
    s = requests.Session()
    s.headers.update(RADAR_HEADERS)
    return s

def radar_search(keyword: str, limit: int = 5) -> List[Dict]:
    try:
        params = {"w": keyword}
        s = radar_session()
        res = s.get(RADAR_SEARCH_URL, params=params, timeout=15)
        res.raise_for_status()
        
        soup = BeautifulSoup(res.text, "lxml")
        results = []
        
        # ê²€ìƒ‰ ê²°ê³¼ ë§í¬ íŒŒì‹±
        links = []
        for a in soup.select('a[href*="search/result?n="]'):
            href = a.get("href")
            if href:
                full_url = urljoin(RADAR_BASE, href)
                if full_url not in links:
                    links.append(full_url)
        
        # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        for url in links[:limit]:
            try:
                detail_res = s.get(url, timeout=15)
                detail_res.raise_for_status()
                detail_soup = BeautifulSoup(detail_res.text, "lxml")
                
                # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                brand = ""
                h1 = detail_soup.select_one("h1")
                if h1:
                    brand = h1.get_text(strip=True)
                
                company = ""
                for a in detail_soup.find_all("a", href=True):
                    href = a["href"].strip()
                    if href.startswith("http") and "rad-ar.or.jp" not in href:
                        company = a.get_text(strip=True)
                        break
                
                # í…Œì´ë¸”ì—ì„œ ì •ë³´ ì¶”ì¶œ
                active_ingredient = ""
                dosage_form = ""
                for tr in detail_soup.select("table tr"):
                    cells = tr.find_all(["td", "th"])
                    if len(cells) >= 2:
                        key = re.sub(r"\s+", " ", cells[0].get_text(strip=True))
                        val = cells[1].get_text(strip=True)
                        if "Active ingredient" in key:
                            active_ingredient = val
                        elif "Dosage form" in key:
                            dosage_form = val
                
                results.append({
                    "brand": brand,
                    "company": company,
                    "active_ingredient": active_ingredient,
                    "dosage_form": dosage_form,
                    "url": url
                })
                
                time.sleep(0.5)  # ìš”ì²­ ê°„ê²©
                
            except Exception as e:
                continue
                
        return results
        
    except Exception as e:
        return []

# ==================== ë©”ì¸ ì•± ====================
@st.cache_resource
def load_rag():
    """ê³ ë„í™”ëœ RAG ì‹œìŠ¤í…œ ë¡œë“œ"""
    return GLOBAL_ADVANCED_RAG

# RAG ë¡œë“œ
rag = load_rag()

with st.form("chat_form"):
    uploaded = st.file_uploader("ì¦ìƒ ì‚¬ì§„ ì—…ë¡œë“œ (ì„ íƒ)", type=["png", "jpg", "jpeg"])
    symptoms = st.text_area("ì¦ìƒ ì„¤ëª…", placeholder="ì˜ˆ) ì´ë§ˆê°€ ì°¢ì–´ì ¸ í”¼ê°€ ë‚˜ìš”, ì—´ì´ 38.5ë„ì˜ˆìš”")
    
    # ìœ„ì¹˜ ì„¤ì • ì„¹ì…˜
    st.subheader("ğŸ“ ìœ„ì¹˜ ì„¤ì •")
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì„ íƒ
    test_mode = st.checkbox("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ëœë¤ ë„ì¿„ ì§€ì—­)", value=False, 
                           help="ì²´í¬í•˜ë©´ ë„ì¿„ì˜ ëœë¤í•œ ì§€ì—­ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤")
    
    if test_mode:
        st.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë„ì¿„ì˜ ëœë¤í•œ ì§€ì—­ì—ì„œ ë³‘ì›/ì•½êµ­ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤")
        location = "Tokyo (Test Mode)"
    else:
        location = st.text_input("í˜„ì¬ ìœ„ì¹˜(ë„ì‹œ/êµ¬ ë‹¨ìœ„, ì¼ë³¸)", value="Tokyo")
        st.write("ë‚´ ìœ„ì¹˜ ì‚¬ìš©(ë¸Œë¼ìš°ì € ê¶Œí•œ í•„ìš”):")
        loc = streamlit_geolocation()
    
    traveler = st.checkbox("ì—¬í–‰ì ëª¨ë“œ(í•œêµ­â†’ì¼ë³¸)", value=True)
    submitted = st.form_submit_button("ìƒë‹´í•˜ê¸°")

if submitted:
    # ë¡œê¹…ì„ ìœ„í•œ ì‹œì‘ ì‹œê°„
    start_time = time.time()
    session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    with st.spinner("ë¶„ì„ ì¤‘..."):
        # ì´ë¯¸ì§€ ë¶„ì„
        findings = []
        image_uploaded = uploaded is not None
        if uploaded is not None:
            try:
                img = Image.open(uploaded).convert("RGB")
                findings = simple_image_screening(img)
                
                # ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„° ì¤€ë¹„
                img_bytes = uploaded.getvalue()
                emg_img = detect_emergency_from_image(img, img_bytes)
                if emg_img:
                    findings.extend(emg_img)
            except Exception as e:
                findings = ["ì´ë¯¸ì§€ í•´ì„ ì‹¤íŒ¨"]
        
        # ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ì¡°ì–¸
        rule_out = simple_text_rules(symptoms)
        advice = rule_out["advice"]
        otc = rule_out["otc"]
        
        # ê³ ë„í™”ëœ RAG ê²€ìƒ‰
        rag_results = []
        rag_confidence = 0.0
        try:
            # ê³ ë„í™”ëœ ê²€ìƒ‰: ì¿¼ë¦¬ í™•ì¥, Dense+Sparse ê²°í•©, ë¦¬ë­í‚¹ í¬í•¨
            hits = rag.search(symptoms, top_k=3, use_reranking=True)
            passages = [h[0] for h in hits]
            rag_results = hits
            rag_confidence = max([score for _, score in hits]) if hits else 0.0
            evidence_titles = []
            for txt, score in hits:
                first = (txt.strip().splitlines() or [""])[0].strip()
                evidence_titles.append(f"{first[:60]}... (ì‹ ë¢°ë„: {score:.2f})" if first else "ê·¼ê±° ë¬¸ì„œ")
            
            # RAG ì‹œìŠ¤í…œ í†µê³„ í‘œì‹œ (ë””ë²„ê¹…ìš©)
            if st.checkbox("ğŸ” RAG ì‹œìŠ¤í…œ í†µê³„ ë³´ê¸°", value=False):
                stats = rag.get_search_stats()
                st.json(stats)
                
        except Exception as e:
            passages = []
            evidence_titles = []
            st.error(f"RAG ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        # ì§€ì˜¤ ê²€ìƒ‰
        nearby_hospitals = []
        nearby_pharmacies = []
        try:
            if test_mode:
                # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë„ì¿„ì˜ ëœë¤í•œ ì§€ì—­ ì‚¬ìš©
                lat, lon = random_tokyo_latlon()
                st.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ({lat:.4f}, {lon:.4f}) ìœ„ì¹˜ì—ì„œ ê²€ìƒ‰ ì¤‘...")
            elif loc and loc.get("latitude") and loc.get("longitude"):
                # ì‹¤ì œ ìœ„ì¹˜ ì‚¬ìš© (ë¸Œë¼ìš°ì € GPS)
                lat, lon = loc["latitude"], loc["longitude"]
                st.info(f"ğŸ“ ì‹¤ì œ ìœ„ì¹˜: ({lat:.4f}, {lon:.4f})")
            else:
                # ì…ë ¥ëœ ìœ„ì¹˜ë¡œ ê²€ìƒ‰
                geo = geocode_place(location)
                if geo:
                    lat, lon = geo["lat"], geo["lon"]
                    st.info(f"ğŸ“ ê²€ìƒ‰ëœ ìœ„ì¹˜: {location} ({lat:.4f}, {lon:.4f})")
                else:
                    lat, lon = 35.676203, 139.650311  # Tokyo fallback
                    st.warning(f"âš ï¸ ìœ„ì¹˜ ê²€ìƒ‰ ì‹¤íŒ¨, ë„ì¿„ ê¸°ë³¸ ìœ„ì¹˜ ì‚¬ìš©: ({lat:.4f}, {lon:.4f})")
            
            nearby_hospitals = search_hospitals(lat, lon, 2000)
            nearby_pharmacies = search_pharmacies(lat, lon, 1500)
        except Exception as e:
            st.error(f"ìœ„ì¹˜ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            pass
        
        # ì‘ê¸‰ìƒí™© ê°ì§€
        emergency_reasons = detect_emergency(symptoms)
        if findings:
            for f in findings:
                if any(s in f.lower() for s in ["ì¶œí˜ˆ", "bleeding", "í™”ìƒ", "burn"]):
                    emergency_reasons.append(f)
        
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ í‘œì‹œ
        if uploaded is not None:
            st.subheader("ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
            st.image(uploaded, caption="ì¦ìƒ ì‚¬ì§„", use_container_width=True)
        
        if emergency_reasons:
            st.error("ìœ„ê¸‰ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ 119ë¡œ ì „í™”í•˜ì„¸ìš”.")
            st.write("ê·¼ê±°: ", ", ".join(emergency_reasons))
            col_a, col_b = st.columns(2)
            with col_a:
                st.link_button("í˜„ì§€ 119 ì—°ê²°", "tel:119")
            with col_b:
                st.link_button("í•œêµ­ ê¸´ê¸‰ ì§€ì›(ì¬ì™¸êµ­ë¯¼)", "tel:+82232100404")
            st.caption("ì°¸ê³ : í•´ì™¸ì—ì„œ í•œêµ­ 119 ì§ì ‘ ì—°ê²°ì€ ë¶ˆê°€í•˜ë©°, ì¬ì™¸êµ­ë¯¼ ê¸´ê¸‰ì „í™”ë¡œ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.subheader("ì¡°ì–¸")
            st.write(advice)
            
            if findings:
                st.write("ì´ë¯¸ì§€ ì°¸ê³ : " + ", ".join(findings))
            
            if otc:
                st.subheader("ê¶Œì¥ OTC")
                st.write(", ".join(otc))
                
                # OTC ì´ë¯¸ì§€ í‘œì‹œ
                otc_images = map_otc_to_images(otc)
                if otc_images:
                    st.caption("ëŒ€í‘œ ì´ë¯¸ì§€")
                    cols = st.columns(min(4, len(otc_images)))
                    for i, img in enumerate(otc_images):
                        with cols[i % len(cols)]:
                            st.write(img)
                
                if traveler:
                    brands = map_otc_to_brands(otc)
                    if brands:
                        st.caption("êµ¬ë§¤ ì‹œ ì°¸ê³ (ì„±ë¶„/ì¹´í…Œê³ ë¦¬):")
                        for b in brands:
                            st.write(f"- {b}")
                    
                    jp_phrase = build_jp_phrase(symptoms, otc)
                    st.subheader("ì•½êµ­ì—ì„œ ë³´ì—¬ì¤„ ì¼ë³¸ì–´ ë¬¸ì¥")
                    st.code(jp_phrase)
            
            # ë³‘ì› ì •ë³´ í‘œì‹œ
            if nearby_hospitals:
                st.subheader("ê·¼ì²˜ ë³‘ì›")
                for h in nearby_hospitals[:5]:
                    name = h.get('name', 'Unknown')
                    address = h.get('address', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')
                    lat = h.get('lat')
                    lon = h.get('lon')
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"- **{name}**")
                        st.write(f"  ğŸ“ {address}")
                    with col2:
                        if lat and lon:
                            map_link = build_google_maps_link(lat, lon, name)
                            if map_link:
                                st.link_button("ğŸ—ºï¸ ì§€ë„", map_link)
            
            # ì•½êµ­ ì •ë³´ í‘œì‹œ
            if nearby_pharmacies:
                st.subheader("ê·¼ì²˜ ì•½êµ­")
                for p in nearby_pharmacies[:5]:
                    name = p.get('name', 'Unknown')
                    address = p.get('address', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')
                    lat = p.get('lat')
                    lon = p.get('lon')
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"- **{name}**")
                        st.write(f"  ğŸ“ {address}")
                    with col2:
                        if lat and lon:
                            map_link = build_google_maps_link(lat, lon, name)
                            if map_link:
                                st.link_button("ğŸ—ºï¸ ì§€ë„", map_link)
            
            if evidence_titles:
                st.subheader("ê·¼ê±° ë¬¸ì„œ")
                for t in evidence_titles:
                    st.write(f"- {t}")
            
            # ì˜ì•½í’ˆ ê²€ìƒ‰ ì„¹ì…˜
            if otc:
                st.subheader("ì¼ë³¸ ì˜ì•½í’ˆ ì •ë³´ ê²€ìƒ‰")
                drug_keywords = []
                for o in otc:
                    if "í•´ì—´" in o or "acet" in o.lower():
                        drug_keywords.append("acetaminophen")
                    elif "ì§€ì‚¬" in o:
                        drug_keywords.append("antidiarrheal")
                    elif "ì œì‚°" in o or "ìœ„ì‚°" in o:
                        drug_keywords.append("antacid")
                    elif "ì§„í†µ" in o:
                        drug_keywords.append("analgesic")
                    elif "í•­íˆìŠ¤íƒ€ë¯¼" in o:
                        drug_keywords.append("antihistamine")
                
                if drug_keywords:
                    with st.spinner("ì¼ë³¸ ì˜ì•½í’ˆ ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘..."):
                        for keyword in drug_keywords[:2]:  # ìµœëŒ€ 2ê°œ í‚¤ì›Œë“œë§Œ ê²€ìƒ‰
                            try:
                                drug_results = radar_search(keyword, limit=3)
                                if drug_results:
                                    st.write(f"**{keyword} ê´€ë ¨ ì˜ì•½í’ˆ:**")
                                    for drug in drug_results:
                                        with st.expander(f"ğŸ’Š {drug.get('brand', 'Unknown')}"):
                                            if drug.get('company'):
                                                st.write(f"**ì œì¡°ì‚¬:** {drug['company']}")
                                            if drug.get('active_ingredient'):
                                                st.write(f"**ì£¼ì„±ë¶„:** {drug['active_ingredient']}")
                                            if drug.get('dosage_form'):
                                                st.write(f"**ì œí˜•:** {drug['dosage_form']}")
                                            if drug.get('url'):
                                                st.link_button("ìƒì„¸ ì •ë³´ ë³´ê¸°", drug['url'])
                            except Exception as e:
                                st.write(f"ì˜ì•½í’ˆ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {keyword}")
                                continue
            
            st.caption("ì¼ë³¸ í˜„ì§€ ë“œëŸ­ìŠ¤í† ì–´/ì•½êµ­(Matsumoto Kiyoshi, Welcia ë“±)ì—ì„œ êµ¬ë§¤ ê°€ëŠ¥")
        
        # ë¡œê¹… ì™„ë£Œ
        processing_time = time.time() - start_time
        
        # ì‘ë‹µ í’ˆì§ˆ í‰ê°€
        default_advice = "ì¦ìƒì— ëŒ€í•œ ê¸°ë³¸ ì‘ê¸‰ì²˜ì¹˜ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤. ì‹¬ê°í•œ ì¦ìƒì´ë©´ ì¦‰ì‹œ 119(ì¼ë³¸: 119)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”."
        is_default_advice = advice.strip() == default_advice.strip()
        
        advice_quality = "good" if rag_confidence > 0.5 and len(rag_results) > 0 and not is_default_advice else "poor"
        
        # ê¸°ë³¸ ì¡°ì–¸ì¸ ê²½ìš° ì‹¤íŒ¨ë¡œ ê°„ì£¼
        if is_default_advice:
            advice_quality = "failed"
        
        # ìœ„ì¹˜ ì •ë³´
        location_coords = None
        if not test_mode and loc and 'latitude' in loc and 'longitude' in loc:
            location_coords = (loc['latitude'], loc['longitude'])
        
        # ë¡œê·¸ ê¸°ë¡ (ë°°í¬ìš©ì—ì„œëŠ” ë¹„í™œì„±í™”)
        # try:
        #     log_id = symptom_logger.log_symptom(
        #         user_input=symptoms,
        #         image_uploaded=image_uploaded,
        #         rag_results=rag_results,
        #         advice_generated=bool(advice),
        #         advice_quality=advice_quality,
        #         hospital_found=len(nearby_hospitals) > 0,
        #         pharmacy_found=len(nearby_pharmacies) > 0,
        #         location=location_coords,
        #         processing_time=processing_time,
        #         session_id=session_id
        #     )
        # except Exception as e:
        #     pass
        
        # ê¸°ë³¸ ì¡°ì–¸ì¸ ê²½ìš° ìë™ í¬ë¡¤ë§ íŠ¸ë¦¬ê±° (ë°°í¬ìš©ì—ì„œëŠ” ë¹„í™œì„±í™”)
        # if is_default_advice:
        #     try:
        #         st.info("ğŸ” ìƒˆë¡œìš´ ì¦ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤...")
        #         # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìë™ í¬ë¡¤ë§ ì‹¤í–‰
        #         auto_crawl_unhandled_symptoms()
        #         st.success("âœ… ìƒˆë¡œìš´ ì˜ë£Œ ì •ë³´ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒì— ë” ì •í™•í•œ ì¡°ì–¸ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        #     except Exception as e:
        #         st.warning(f"âš ï¸ ìë™ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
