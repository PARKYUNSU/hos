import os
import streamlit as st
from streamlit_geolocation import streamlit_geolocation
import requests
import pathlib
import re
from typing import List, Tuple, Dict, Optional
from rank_bm25 import BM25Okapi
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from PIL import Image
import numpy as np
import base64
import json
import time
import sys
from datetime import datetime

# ë°±ì—”ë“œ ì„œë¹„ìŠ¤ ì„í¬íŠ¸
sys.path.append('backend')
from services_logging import symptom_logger

st.set_page_config(page_title="ì‘ê¸‰ ì±—ë´‡", page_icon="ğŸš‘", layout="centered")
st.title("ì‘ê¸‰ í™˜ì ì±—ë´‡ (ì¼ë³¸)")
st.caption("ì¼ë³¸ ì—¬í–‰ìë¥¼ ìœ„í•œ ì‘ê¸‰ ì˜ë£Œ ì¡°ì–¸ - VLM/LLM/RAG í†µí•©")

# ==================== RAG ì‹œìŠ¤í…œ ====================
class HybridRAG:
    def __init__(self, passages: List[str]):
        self.passages = passages
        self.tokenized = [self._tokenize(p) for p in passages]
        self.bm25 = BM25Okapi(self.tokenized)
        self.vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=8000)
        self.tfidf = self.vectorizer.fit_transform(passages)

    def _tokenize(self, text: str) -> List[str]:
        tokens = re.findall(r'\b\w+\b', text.lower())
        return tokens

    def search(self, query: str, top_k: int = 5) -> List[Tuple[str, float]]:
        if not query:
            return []
        q_tokens = self._tokenize(query)
        bm_scores = self.bm25.get_scores(q_tokens)
        q_vec = self.vectorizer.transform([query])
        tf_scores = cosine_similarity(q_vec, self.tfidf)[0]
        scores = [(i, 0.6 * bm_scores[i] + 0.4 * tf_scores[i]) for i in range(len(self.passages))]
        scores.sort(key=lambda x: x[1], reverse=True)
        idxs = [i for i, _ in scores[:top_k]]
        return [(self.passages[i], float(scores[j][1])) for j, i in enumerate(idxs)]

def load_disk_passages() -> list[str]:
    root = pathlib.Path(__file__).resolve().parents[1]
    pdir = root / "data" / "passages" / "jp"
    if not pdir.exists():
        return []
    out = []
    for p in sorted(pdir.glob("*.txt")):
        try:
            out.append(p.read_text(encoding="utf-8"))
        except Exception:
            continue
    return out

DEFAULT_PASSAGES = [
    "ç†±ãŒã‚ã‚‹ã¨ãã¯ã¬ã‚‹ã¾æ¹¯ã§ä½“ã‚’å†·ã‚„ã—ã€æ°´åˆ†ã‚’ååˆ†ã«ã¨ã‚Šã¾ã—ã‚‡ã†ã€‚ã‚¢ã‚»ãƒˆã‚¢ãƒŸãƒãƒ•ã‚§ãƒ³ã¯æ¯”è¼ƒçš„å®‰å…¨ã§ã™ã€‚",
    "å‡ºè¡€ã—ã¦ã„ã‚‹å‚·ã¯ç›´æ¥åœ§è¿«ã§æ­¢è¡€ã—ã€ãã‚Œã„ãªæ°´ã§æ´—æµ„å¾Œã€æ»…èŒã‚¬ãƒ¼ã‚¼ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚",
    "ä¸‹ç—¢ã®ã¨ãã¯æ°´åˆ†ãƒ»é›»è§£è³ªã®è£œçµ¦ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚ç—‡çŠ¶ãŒé‡ã„å ´åˆã¯å—è¨ºã—ã¦ãã ã•ã„ã€‚",
]

# ==================== ì§€ì˜¤ ì„œë¹„ìŠ¤ ====================
NOMINATIM_URL = "https://nominatim.openstreetmap.org/search"
OVERPASS_URLS = [
    "https://overpass-api.de/api/interpreter",
    "https://lz4.overpass-api.de/api/interpreter",
    "https://overpass.kumi.systems/api/interpreter",
]
REVERSE_URL = "https://nominatim.openstreetmap.org/reverse"

def _headers() -> Dict[str, str]:
    contact = os.getenv("CONTACT_EMAIL", "hos-emergency-bot/0.1")
    return {"User-Agent": f"hos-emergency-bot/0.1 ({contact})"}

def geocode_place(place: str) -> Optional[Dict[str, float]]:
    if not place:
        return None
    QUICK: Dict[str, Tuple[float, float]] = {
        "shibuya": (35.661777, 139.704051),
        "tokyo": (35.676203, 139.650311),
        "japan": (36.204824, 138.252924),
    }
    key = (place or "").strip().lower()
    if key in QUICK:
        lat, lon = QUICK[key]
        return {"lat": lat, "lon": lon}
    params = {
        "q": place,
        "format": "json",
        "limit": 1,
        "addressdetails": 0,
    }
    try:
        r = requests.get(NOMINATIM_URL, params=params, headers=_headers(), timeout=6)
        if not r.ok:
            return None
        arr = r.json()
        if not arr:
            return None
        lat = float(arr[0]["lat"])
        lon = float(arr[0]["lon"])
        return {"lat": lat, "lon": lon}
    except Exception:
        return QUICK.get("tokyo") and {"lat": QUICK["tokyo"][0], "lon": QUICK["tokyo"][1]}

def reverse_geocode(lat: float, lon: float) -> str:
    try:
        params = {"format": "json", "lat": lat, "lon": lon, "zoom": 18, "addressdetails": 1}
        r = requests.get(REVERSE_URL, params=params, headers=_headers(), timeout=6)
        if not r.ok:
            return ""
        data = r.json()
        address = data.get("display_name") or ""
        return address or ""
    except Exception:
        return ""

def build_address_from_tags(tags: Dict[str, str]) -> str:
    parts: List[str] = []
    # Common OSM address tags in Japan
    for key in [
        "addr:prefecture",
        "addr:city", 
        "addr:ward",
        "addr:district",
        "addr:suburb",
        "addr:neighbourhood",
        "addr:street",
        "addr:block",
        "addr:housenumber",
        "addr:postcode",
    ]:
        val = tags.get(key)
        if val:
            parts.append(val)
    if not parts:
        # fallback single fields
        for key in ["addr:full", "addr:place", "addr:hamlet"]:
            val = tags.get(key)
            if val:
                parts.append(val)
                break
    return " ".join(parts)

def search_hospitals(lat: float, lon: float, radius_m: int = 2000) -> List[Dict]:
    query = f"""
    [out:json][timeout:6];
    (
      node["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
      way["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
      relation["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
    );
    out center 20;
    """
    r = None
    for endpoint in OVERPASS_URLS:
        try:
            r = requests.post(endpoint, data={"data": query}, timeout=7)
            if r.ok:
                break
        except Exception:
            r = None
            continue
    if r is None:
        return []
    results: List[Dict] = []
    if r.ok:
        data = r.json()
        for el in data.get("elements", [])[:20]:
            tags = el.get("tags", {})
            name = tags.get("name") or tags.get("name:en") or tags.get("name:ja") or "Unknown"
            lat_out = el.get("lat") or (el.get("center") or {}).get("lat")
            lon_out = el.get("lon") or (el.get("center") or {}).get("lon")
            
            # ì£¼ì†Œ ì •ë³´ êµ¬ì„±
            addr = build_address_from_tags(tags)
            if not addr and lat_out and lon_out:
                addr = reverse_geocode(lat_out, lon_out)
            
            results.append({
                "name": name,
                "address": addr or f"ìœ„ë„: {lat_out:.4f}, ê²½ë„: {lon_out:.4f}",
                "lat": lat_out,
                "lon": lon_out,
            })
    return results

def search_pharmacies(lat: float, lon: float, radius_m: int = 1500) -> List[Dict]:
    query = f"""
    [out:json][timeout:7];
    (
      node["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
      way["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
      relation["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
    );
    out center 30;
    """
    r = None
    for endpoint in OVERPASS_URLS:
        try:
            r = requests.post(endpoint, data={"data": query}, timeout=7)
            if r.ok:
                break
        except Exception:
            r = None
            continue
    if r is None:
        return []
    results: List[Dict] = []
    if r.ok:
        data = r.json()
        for el in data.get("elements", [])[:30]:
            tags = el.get("tags", {})
            name = tags.get("name") or tags.get("name:en") or tags.get("name:ja") or "Unknown"
            lat_out = el.get("lat") or (el.get("center") or {}).get("lat")
            lon_out = el.get("lon") or (el.get("center") or {}).get("lon")
            
            # ì£¼ì†Œ ì •ë³´ êµ¬ì„±
            addr = build_address_from_tags(tags)
            if not addr and lat_out and lon_out:
                addr = reverse_geocode(lat_out, lon_out)
            
            results.append({
                "name": name,
                "address": addr or f"ìœ„ë„: {lat_out:.4f}, ê²½ë„: {lon_out:.4f}",
                "lat": lat_out,
                "lon": lon_out,
            })
    return results

# ==================== ê¸°ë³¸ ê·œì¹™ ====================
def simple_text_rules(symptoms_text: str) -> dict:
    t = (symptoms_text or "").lower()
    advice = "ì¦ìƒì— ëŒ€í•œ ê¸°ë³¸ ì‘ê¸‰ì²˜ì¹˜ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤. ì‹¬ê°í•œ ì¦ìƒì´ë©´ ì¦‰ì‹œ 119(ì¼ë³¸: 119)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”."
    otc: list = []
    
    if any(k in t for k in ["fever", "ì—´", "ç™ºç†±"]):
        otc.append("í•´ì—´ì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)")
    if any(k in t for k in ["cough", "ê¸°ì¹¨", "å’³"]):
        otc.append("ì§„í•´ê±°ë‹´ì œ")
    if any(k in t for k in ["diarrhea", "ì„¤ì‚¬", "ä¸‹ç—¢"]):
        otc.append("ì§€ì‚¬ì œ ë° ìˆ˜ë¶„ë³´ì¶©")
    if any(k in t for k in ["abdominal pain", "stomach ache", "ë°°ì•„í””", "ë³µí†µ", "è…¹ç—›"]):
        otc.extend(["ì œì‚°ì œ/ìœ„ì‚°ì–µì œì œ(ì¦ìƒì— ë”°ë¼)", "ê°€ìŠ¤ì™„í™”ì œ(ì‹œë©”í‹°ì½˜)", "ì§„í†µì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)"])
    if any(k in t for k in ["headache", "ë‘í†µ", "é ­ç—›"]):
        if "í•´ì—´ì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)" not in otc:
            otc.append("ì§„í†µì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)")
    if any(k in t for k in ["vomit", "vomiting", "êµ¬í† ", "å˜”å", "íƒˆìˆ˜", "dehydration"]):
        otc.append("ê²½êµ¬ìˆ˜ë¶„ë³´ì¶©ì•¡(ORS)")
    if any(k in t for k in ["rash", "ë°œì§„", "ì•Œë ˆë¥´ê¸°", "è•éº»ç–¹", "ã˜ã‚“ã¾ã—ã‚“", "allergy"]):
        otc.append("í•­íˆìŠ¤íƒ€ë¯¼ì œ")
    if any(k in t for k in ["sore throat", "ì¸í›„í†µ", "ëª©ì•„í””", "å–‰ã®ç—›ã¿"]):
        otc.append("ëª©ì—¼ì¦ ì™„í™” ëª©ìº”ë””/ë¡œì  ì§€")
    if any(k in t for k in ["stuffy nose", "nasal congestion", "ì½”ë§‰í˜", "é¼»ã¥ã¾ã‚Š"]):
        otc.append("ë¹„ì¶©í˜ˆ ì œê±°ì œ(ë””ì½˜ì œìŠ¤í„´íŠ¸)")
    if any(k in t for k in ["toothache", "ì¹˜í†µ", "æ­¯ç—›"]):
        if "ì§„í†µì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)" not in otc:
            otc.append("ì§„í†µì œ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)")
    if any(k in t for k in ["cut", "bleeding", "ìƒì²˜", "å‡ºè¡€"]):
        advice = "ìƒì²˜ ë¶€ìœ„ë¥¼ ì••ë°•í•˜ì—¬ ì§€í˜ˆí•˜ê³ , ê¹¨ë—í•œ ë¬¼ë¡œ ì„¸ì²™ í›„ ë©¸ê·  ê±°ì¦ˆë¥¼ ì ìš©í•˜ì„¸ìš”. ì‹¬í•œ ì¶œí˜ˆì€ ì¦‰ì‹œ 119."
    
    # ë²Œë ˆ/ë§ë²Œ ì˜ì„
    if any(k in t for k in ["ë²Œë ˆ", "ë§ë²Œ", "ë²Œ", "ì˜ì„", "ë¬¼ë¦¼", "ë²Œë ˆì— ë¬¼ë¦¼", "ë§ë²Œì— ì˜ì„", "ë²Œì— ì˜ì„", "insect bite", "wasp sting", "bee sting", "è™«ã«åˆºã•ã‚ŒãŸ", "èœ‚ã«åˆºã•ã‚ŒãŸ"]):
        advice = "ë²Œë ˆ/ë§ë²Œ ì˜ì„: ì¦‰ì‹œ ì¹¨ì„ ì œê±°í•˜ê³ , ê¹¨ë—í•œ ë¬¼ë¡œ ì„¸ì²™í•˜ì„¸ìš”. ì–¼ìŒì°œì§ˆë¡œ ë¶€ì¢…ì„ ì™„í™”í•˜ê³ , í•­íˆìŠ¤íƒ€ë¯¼ ì—°ê³ ë¥¼ ë°”ë¥´ì„¸ìš”. í˜¸í¡ê³¤ë€, ì „ì‹  ë‘ë“œëŸ¬ê¸°, ì˜ì‹ ë³€í™” ì‹œ ì¦‰ì‹œ 119."
        otc.extend(["í•­íˆìŠ¤íƒ€ë¯¼ ì—°ê³ ", "í•­íˆìŠ¤íƒ€ë¯¼ì œ(ê²½êµ¬)", "ì†Œë…ì œ", "ì–¼ìŒíŒ©"])
    
    return {"advice": advice, "otc": otc}

# ==================== ì‘ê¸‰ìƒí™© ê°ì§€ ====================
CRITICAL_KEYWORDS = [
    "chest pain", "ì‹¬í•œ ê°€ìŠ´ í†µì¦", "èƒ¸ã®æ¿€ç—›",
    "severe bleeding", "ëŒ€ëŸ‰ ì¶œí˜ˆ", "å¤§é‡å‡ºè¡€",
    "unconscious", "ì˜ì‹ ì—†ìŒ", "æ„è­˜ãªã—",
    "stroke", "í¸ë§ˆë¹„", "è„³å’ä¸­",
    "difficulty breathing", "ìˆ¨ì´ ê°€ì¨", "å‘¼å¸å›°é›£",
    "severe abdominal pain", "ë³µë¶€ ê·¹ì‹¬í•œ í†µì¦", "æ¿€ã—ã„è…¹ç—›",
    "anaphylaxis", "ì•„ë‚˜í•„ë½ì‹œìŠ¤", "ì‹¬í•œ ì•Œë ˆë¥´ê¸° ë°˜ì‘", "ì „ì‹  ë‘ë“œëŸ¬ê¸°", "í˜¸í¡ê³¤ë€",
    "severe allergic reaction", "å…¨èº«è•éº»ç–¹", "å‘¼å¸å›°é›£",
]

def detect_emergency(symptoms_text: str) -> list:
    t = (symptoms_text or "").lower()
    reasons: list = []
    for k in CRITICAL_KEYWORDS:
        if k in t:
            reasons.append(k)
    return reasons

# ==================== ì´ë¯¸ì§€ ë¶„ì„ ====================
def simple_image_screening(img: Image.Image) -> List[str]:
    w, h = img.size
    findings: List[str] = []
    if min(w, h) < 128:
        findings.append("ì €í•´ìƒë„ ì´ë¯¸ì§€")
    return findings

def detect_emergency_from_image(img: Image.Image, raw_image: bytes = None) -> List[str]:
    reasons: List[str] = []
    red_thr = 0.25
    burn_thr = 0.30
    
    # íœ´ë¦¬ìŠ¤í‹± ë¶„ì„
    try:
        small = img.resize((224, 224))
        hsv = small.convert("HSV")
        arr = np.array(hsv)
        h = arr[:, :, 0].astype(np.float32)
        s = arr[:, :, 1].astype(np.float32)
        v = arr[:, :, 2].astype(np.float32)
        
        red_mask = ((h < 10) | (h > 245)) & (s > 100) & (v > 60)
        red_ratio = float(red_mask.mean())
        if red_ratio > red_thr:
            reasons.append("ì´ë¯¸ì§€ìƒ ê³¼ë‹¤ ì¶œí˜ˆ ì˜ì‹¬")
            
        orange_mask = (h >= 10) & (h <= 50) & (s > 120) & (v > 120)
        orange_ratio = float(orange_mask.mean())
        if orange_ratio > burn_thr:
            reasons.append("ì´ë¯¸ì§€ìƒ í™”ìƒ/ê´‘ë²”ìœ„ í™ë°˜ ì˜ì‹¬")
    except Exception:
        pass
    
    # OpenAI Vision API ë¶„ì„ (í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ëœ ê²½ìš°)
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key and raw_image:
            import openai
            client = openai.OpenAI(api_key=api_key)
            
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            import base64
            from io import BytesIO
            
            img_buffer = BytesIO()
            img.save(img_buffer, format="JPEG")
            img_bytes = img_buffer.getvalue()
            b64_image = base64.b64encode(img_bytes).decode("utf-8")
            
            # ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ í”„ë¡¬í”„íŠ¸
            prompt = """
            ì´ ì˜ë£Œ/ìƒí•´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ í•­ëª©ë“¤ì„ í™•ì¸í•˜ê³  ë°œê²¬ëœ ê²ƒë§Œ í•œêµ­ì–´ë¡œ ë³´ê³ í•´ì£¼ì„¸ìš”:
            
            ì‘ê¸‰ìƒí™©:
            - ì‹¬í•œ ì¶œí˜ˆ (ê³¼ë‹¤ ì¶œí˜ˆ, ëŒ€ëŸ‰ ì¶œí˜ˆ)
            - ì‹¬í•œ í™”ìƒ (2ë„ ì´ìƒ í™”ìƒ, ê´‘ë²”ìœ„ í™”ìƒ)
            - ë¼ˆ ë…¸ì¶œ (ê³¨ì ˆ, ê°œë°©ì„± ê³¨ì ˆ)
            - ì ˆë‹¨ìƒ (ì†ê°€ë½, íŒ”, ë‹¤ë¦¬ ì ˆë‹¨)
            - ì¤‘ì¦ ì™¸ìƒ (ì‹¬ê°í•œ ìƒì²˜, ê¹Šì€ ìƒì²˜)
            
            ì¼ë°˜ ì˜ë£Œìƒí™©:
            - ë°œì§„, ì•Œë ˆë¥´ê¸° ë°˜ì‘
            - ë¶€ì¢…, ë¶“ê¸°
            - ë©, íƒ€ë°•ìƒ
            - ê°€ë²¼ìš´ ìƒì²˜, ì°°ê³¼ìƒ
            - í”¼ë¶€ì—¼, ìŠµì§„
            - ë¬¼ì§‘, ìˆ˜í¬
            
            ë°œê²¬ëœ ì¦ìƒì´ ì—†ìœ¼ë©´ "ì •ìƒ"ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.
            """
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{b64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500,
                temperature=0.1
            )
            
            analysis = response.choices[0].message.content.strip()
            
            # ì‘ê¸‰ìƒí™© í‚¤ì›Œë“œ ì²´í¬
            emergency_keywords = ["ì‹¬í•œ ì¶œí˜ˆ", "ê³¼ë‹¤ ì¶œí˜ˆ", "ëŒ€ëŸ‰ ì¶œí˜ˆ", "ì‹¬í•œ í™”ìƒ", "2ë„ ì´ìƒ", "ê´‘ë²”ìœ„ í™”ìƒ", 
                                "ë¼ˆ ë…¸ì¶œ", "ê³¨ì ˆ", "ê°œë°©ì„±", "ì ˆë‹¨", "ì¤‘ì¦ ì™¸ìƒ", "ì‹¬ê°í•œ ìƒì²˜", "ê¹Šì€ ìƒì²˜"]
            
            for keyword in emergency_keywords:
                if keyword in analysis:
                    reasons.append(f"AI ë¶„ì„: {analysis}")
                    break
            else:
                # ì‘ê¸‰ìƒí™©ì´ ì•„ë‹Œ ê²½ìš° ì¼ë°˜ ì˜ë£Œìƒí™©ìœ¼ë¡œ ë¶„ë¥˜
                if "ì •ìƒ" not in analysis and analysis:
                    reasons.append(f"AI ë¶„ì„: {analysis}")
                    
    except Exception as e:
        # OpenAI API ì˜¤ë¥˜ ì‹œ íœ´ë¦¬ìŠ¤í‹± ê²°ê³¼ë§Œ ì‚¬ìš©
        pass
    
    return reasons

# ==================== ì¼ë³¸ì–´ ë¬¸ì¥ ìƒì„± ====================
def build_jp_phrase(symptoms_text: str, otc: list) -> str:
    base = "è–¬å±€ã§ç›¸è«‡ã—ãŸã„ã§ã™ã€‚"
    if any("ì§€ì‚¬ì œ" in o or "ì„¤ì‚¬" in symptoms_text for o in otc) or ("ì„¤ì‚¬" in (symptoms_text or "")):
        return base + "ã€è…¹ç—›ã‚„ä¸‹ç—¢ãŒã‚ã‚Šã¾ã™ã€‚å¸‚è²©ã®æ•´è…¸å‰¤ã‚„ä¸‹ç—¢æ­¢ã‚ã‚’æ¢ã—ã¦ã„ã¾ã™ã€‚ã€"
    if any("í•´ì—´" in o or "ì—´" in symptoms_text for o in otc) or ("ë°œì—´" in (symptoms_text or "") or "ì—´" in (symptoms_text or "")):
        return base + "ã€ç™ºç†±ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚»ãƒˆã‚¢ãƒŸãƒãƒ•ã‚§ãƒ³æˆåˆ†ã®è§£ç†±è–¬ã‚’æ¢ã—ã¦ã„ã¾ã™ã€‚ã€"
    if any("ì§„í•´" in o or "ê¸°ì¹¨" in symptoms_text for o in otc) or ("å’³" in (symptoms_text or "")):
        return base + "ã€å’³ãŒã‚ã‚Šã¾ã™ã€‚å¸‚è²©ã®é®å’³å»ç—°è–¬ã‚’æ¢ã—ã¦ã„ã¾ã™ã€‚ã€"
    return base + "ã€ç—‡çŠ¶ã«åˆã†ä¸€èˆ¬ç”¨åŒ»è–¬å“ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ã€"

def map_otc_to_brands(otc: list) -> list:
    hints: list = []
    for o in otc:
        lo = o.lower()
        if "í•´ì—´" in o or "acet" in lo:
            hints.append("è§£ç†±è–¬: ã‚¢ã‚»ãƒˆã‚¢ãƒŸãƒãƒ•ã‚§ãƒ³é…åˆè£½å“")
        if "ì§€ì‚¬" in o:
            hints.append("ä¸‹ç—¢æ­¢ã‚/æ•´è…¸å‰¤: ä¹³é…¸èŒ/ãƒ­ãƒšãƒ©ãƒŸãƒ‰ç³»(ç—‡çŠ¶ã«ã‚ˆã‚Š) â€»ç”¨æ³•æ³¨æ„")
        if "ì œì‚°" in o or "ìœ„ì‚°" in o:
            hints.append("èƒƒè–¬: åˆ¶é…¸è–¬/H2ãƒ–ãƒ­ãƒƒã‚«ãƒ¼ç³»(ç—‡çŠ¶ã«ã‚ˆã‚Š) â€»ç›¸äº’ä½œç”¨æ³¨æ„")
        if "ê°€ìŠ¤" in o or "ì‹œë©”í‹°ì½˜" in o:
            hints.append("èƒƒè…¸è–¬: ã‚·ãƒ¡ãƒã‚³ãƒ³é…åˆ")
        if "ì§„í†µì œ" in o:
            hints.append("é®ç—›è–¬: ã‚¢ã‚»ãƒˆã‚¢ãƒŸãƒãƒ•ã‚§ãƒ³å„ªå…ˆ(ã‚¤ãƒ–ãƒ—ãƒ­ãƒ•ã‚§ãƒ³ç­‰ã¯çŠ¶æ³ã§å›é¿)")
        if "ì§„í•´" in o:
            hints.append("å’³æ­¢ã‚: é®å’³å»ç—°è–¬ã‚«ãƒ†ã‚´ãƒª")
        if "í•­íˆìŠ¤íƒ€ë¯¼" in o:
            hints.append("æŠ—ãƒ’ã‚¹ã‚¿ãƒŸãƒ³è–¬: ã‹ã‚†ã¿/è•éº»ç–¹ç­‰")
        if "ê²½êµ¬ìˆ˜ë¶„ë³´ì¶©" in o or "ORS" in o.upper():
            hints.append("çµŒå£è£œæ°´æ¶²(ORS): è„±æ°´æ™‚ã®é›»è§£è³ª/æ°´åˆ†è£œçµ¦")
        if "ë¡œì  ì§€" in o or "ëª©ì—¼ì¦" in o:
            hints.append("ãƒˆãƒ­ãƒ¼ãƒ/ã®ã©é£´: å’½é ­ç—›ç·©å’Œ")
        if "ë¹„ì¶©í˜ˆ" in o or "ë””ì½˜ì œìŠ¤í„´íŠ¸" in o or "decongestant" in lo:
            hints.append("é¼»ã¥ã¾ã‚Š: è¡€ç®¡åç¸®ç‚¹é¼»è–¬(çŸ­æœŸä½¿ç”¨)")
    
    out = []
    for h in hints:
        if h not in out:
            out.append(h)
    return out

# ==================== ì§€ë„ ë§í¬ ìƒì„± ====================
def build_google_maps_link(lat: Optional[float], lon: Optional[float], name: Optional[str] = None) -> Optional[str]:
    if lat is None or lon is None:
        return None
    q = f"{lat},{lon}"
    if name:
        q = name
    return f"https://www.google.com/maps/search/?api=1&query={q}"

# ==================== OTC ì´ë¯¸ì§€ ë§¤í•‘ ====================
def map_otc_to_images(otc: list) -> list:
    urls: list = []
    
    def add_for(cat: str, placeholder: str) -> None:
        # ë¡œì»¬ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í”Œë ˆì´ìŠ¤í™€ë”
        urls.append(placeholder)
    
    for o in otc:
        lo = o.lower()
        if ("í•´ì—´" in o) or ("acet" in lo):
            add_for("acetaminophen", "ğŸ’Š")
        if "ì§€ì‚¬" in o:
            add_for("antidiarrheal", "ğŸ’Š")
        if ("ì œì‚°" in o) or ("ìœ„ì‚°" in o):
            add_for("antacid", "ğŸ’Š")
        if ("ê°€ìŠ¤" in o) or ("ì‹œë©”í‹°ì½˜" in o):
            add_for("simethicone", "ğŸ’Š")
        if "í•­íˆìŠ¤íƒ€ë¯¼" in o:
            add_for("antihistamine", "ğŸ’Š")
        if ("ê²½êµ¬ìˆ˜ë¶„ë³´ì¶©" in o) or ("ors" in lo):
            add_for("ors", "ğŸ’Š")
        if ("ë¡œì  ì§€" in o) or ("ëª©ì—¼ì¦" in o):
            add_for("lozenge", "ğŸ’Š")
        if ("ë¹„ì¶©í˜ˆ" in o) or ("decongestant" in lo) or ("ë””ì½˜ì œìŠ¤í„´íŠ¸" in o):
            add_for("decongestant", "ğŸ’Š")
        if ("í™”ìƒ" in o) or ("burn" in lo):
            add_for("burngel", "ğŸ’Š")
        if ("ë³´ìŠµ" in o) or ("ê±´ì¡°" in o) or ("atopy" in lo) or ("ì•„í† í”¼" in o):
            add_for("emollient", "ğŸ’Š")
    
    # ì¤‘ë³µ ì œê±°
    dedup: list = []
    for u in urls:
        if u not in dedup:
            dedup.append(u)
    return dedup

# ==================== RAD-AR ì˜ì•½í’ˆ ê²€ìƒ‰ ====================
import re
import time
from urllib.parse import urljoin, quote
from bs4 import BeautifulSoup
import json
from pathlib import Path

RADAR_BASE = "https://www.rad-ar.or.jp/siori/english/"
RADAR_SEARCH_URL = urljoin(RADAR_BASE, "search")

RADAR_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
    "Accept-Language": "en,ja;q=0.9,ko;q=0.8",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Referer": RADAR_BASE.rstrip("/") + "/",
}

def radar_session():
    s = requests.Session()
    s.headers.update(RADAR_HEADERS)
    return s

def radar_search(keyword: str, limit: int = 5) -> List[Dict]:
    try:
        params = {"w": keyword}
        s = radar_session()
        res = s.get(RADAR_SEARCH_URL, params=params, timeout=15)
        res.raise_for_status()
        
        soup = BeautifulSoup(res.text, "lxml")
        results = []
        
        # ê²€ìƒ‰ ê²°ê³¼ ë§í¬ íŒŒì‹±
        links = []
        for a in soup.select('a[href*="search/result?n="]'):
            href = a.get("href")
            if href:
                full_url = urljoin(RADAR_BASE, href)
                if full_url not in links:
                    links.append(full_url)
        
        # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        for url in links[:limit]:
            try:
                detail_res = s.get(url, timeout=15)
                detail_res.raise_for_status()
                detail_soup = BeautifulSoup(detail_res.text, "lxml")
                
                # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                brand = ""
                h1 = detail_soup.select_one("h1")
                if h1:
                    brand = h1.get_text(strip=True)
                
                company = ""
                for a in detail_soup.find_all("a", href=True):
                    href = a["href"].strip()
                    if href.startswith("http") and "rad-ar.or.jp" not in href:
                        company = a.get_text(strip=True)
                        break
                
                # í…Œì´ë¸”ì—ì„œ ì •ë³´ ì¶”ì¶œ
                active_ingredient = ""
                dosage_form = ""
                for tr in detail_soup.select("table tr"):
                    cells = tr.find_all(["td", "th"])
                    if len(cells) >= 2:
                        key = re.sub(r"\s+", " ", cells[0].get_text(strip=True))
                        val = cells[1].get_text(strip=True)
                        if "Active ingredient" in key:
                            active_ingredient = val
                        elif "Dosage form" in key:
                            dosage_form = val
                
                results.append({
                    "brand": brand,
                    "company": company,
                    "active_ingredient": active_ingredient,
                    "dosage_form": dosage_form,
                    "url": url
                })
                
                time.sleep(0.5)  # ìš”ì²­ ê°„ê²©
                
            except Exception as e:
                continue
                
        return results
        
    except Exception as e:
        return []

# ==================== ë©”ì¸ ì•± ====================
@st.cache_resource
def load_rag():
    _disk = load_disk_passages()
    return HybridRAG(_disk if _disk else DEFAULT_PASSAGES)

# RAG ë¡œë“œ
rag = load_rag()

with st.form("chat_form"):
    uploaded = st.file_uploader("ì¦ìƒ ì‚¬ì§„ ì—…ë¡œë“œ (ì„ íƒ)", type=["png", "jpg", "jpeg"])
    symptoms = st.text_area("ì¦ìƒ ì„¤ëª…", placeholder="ì˜ˆ) ì´ë§ˆê°€ ì°¢ì–´ì ¸ í”¼ê°€ ë‚˜ìš”, ì—´ì´ 38.5ë„ì˜ˆìš”")
    location = st.text_input("í˜„ì¬ ìœ„ì¹˜(ë„ì‹œ/êµ¬ ë‹¨ìœ„, ì¼ë³¸)", value="Tokyo")
    st.write("ë‚´ ìœ„ì¹˜ ì‚¬ìš©(ë¸Œë¼ìš°ì € ê¶Œí•œ í•„ìš”):")
    loc = streamlit_geolocation()
    traveler = st.checkbox("ì—¬í–‰ì ëª¨ë“œ(í•œêµ­â†’ì¼ë³¸)", value=True)
    submitted = st.form_submit_button("ìƒë‹´í•˜ê¸°")

if submitted:
    # ë¡œê¹…ì„ ìœ„í•œ ì‹œì‘ ì‹œê°„
    start_time = time.time()
    session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    with st.spinner("ë¶„ì„ ì¤‘..."):
        # ì´ë¯¸ì§€ ë¶„ì„
        findings = []
        image_uploaded = uploaded is not None
        if uploaded is not None:
            try:
                img = Image.open(uploaded).convert("RGB")
                findings = simple_image_screening(img)
                
                # ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„° ì¤€ë¹„
                img_bytes = uploaded.getvalue()
                emg_img = detect_emergency_from_image(img, img_bytes)
                if emg_img:
                    findings.extend(emg_img)
            except Exception as e:
                findings = ["ì´ë¯¸ì§€ í•´ì„ ì‹¤íŒ¨"]
                st.write(f"ğŸ” ë””ë²„ê¹…: ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜ = {str(e)}")
        
        # ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ì¡°ì–¸
        rule_out = simple_text_rules(symptoms)
        advice = rule_out["advice"]
        otc = rule_out["otc"]
        
        # ë””ë²„ê¹… ì •ë³´
        st.write(f"ğŸ” ë””ë²„ê¹…: ì…ë ¥ëœ ì¦ìƒ = '{symptoms}'")
        st.write(f"ğŸ” ë””ë²„ê¹…: ì¶”ì²œ OTC = {otc}")
        
        # RAG ê²€ìƒ‰
        rag_results = []
        rag_confidence = 0.0
        try:
            hits = rag.search(symptoms, top_k=3)
            passages = [h[0] for h in hits]
            rag_results = hits
            rag_confidence = max([score for _, score in hits]) if hits else 0.0
            evidence_titles = []
            for txt, _ in hits:
                first = (txt.strip().splitlines() or [""])[0].strip()
                evidence_titles.append(first[:80] if first else "ê·¼ê±° ë¬¸ì„œ")
            st.write(f"ğŸ” ë””ë²„ê¹…: RAG ê²€ìƒ‰ ê²°ê³¼ = {len(hits)}ê°œ")
        except Exception as e:
            passages = []
            evidence_titles = []
            st.write(f"ğŸ” ë””ë²„ê¹…: RAG ê²€ìƒ‰ ì˜¤ë¥˜ = {str(e)}")
        
        # ì§€ì˜¤ ê²€ìƒ‰
        nearby_hospitals = []
        nearby_pharmacies = []
        try:
            if loc and loc.get("latitude") and loc.get("longitude"):
                lat, lon = loc["latitude"], loc["longitude"]
                st.write(f"ğŸ” ë””ë²„ê¹…: ë¸Œë¼ìš°ì € ìœ„ì¹˜ ì‚¬ìš© = {lat}, {lon}")
            else:
                geo = geocode_place(location)
                if geo:
                    lat, lon = geo["lat"], geo["lon"]
                    st.write(f"ğŸ” ë””ë²„ê¹…: ì§€ì˜¤ì½”ë”© ê²°ê³¼ = {lat}, {lon}")
                else:
                    lat, lon = 35.676203, 139.650311  # Tokyo fallback
                    st.write(f"ğŸ” ë””ë²„ê¹…: Tokyo í´ë°± ì‚¬ìš© = {lat}, {lon}")
            
            nearby_hospitals = search_hospitals(lat, lon, 2000)
            nearby_pharmacies = search_pharmacies(lat, lon, 1500)
            st.write(f"ğŸ” ë””ë²„ê¹…: ë³‘ì› {len(nearby_hospitals)}ê°œ, ì•½êµ­ {len(nearby_pharmacies)}ê°œ ë°œê²¬")
        except Exception as e:
            st.write(f"ğŸ” ë””ë²„ê¹…: ì§€ì˜¤ ê²€ìƒ‰ ì˜¤ë¥˜ = {str(e)}")
        
        # ì‘ê¸‰ìƒí™© ê°ì§€
        emergency_reasons = detect_emergency(symptoms)
        if findings:
            for f in findings:
                if any(s in f.lower() for s in ["ì¶œí˜ˆ", "bleeding", "í™”ìƒ", "burn"]):
                    emergency_reasons.append(f)
        
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ í‘œì‹œ
        if uploaded is not None:
            st.subheader("ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
            st.image(uploaded, caption="ì¦ìƒ ì‚¬ì§„", use_column_width=True)
        
        if emergency_reasons:
            st.error("ìœ„ê¸‰ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ 119ë¡œ ì „í™”í•˜ì„¸ìš”.")
            st.write("ê·¼ê±°: ", ", ".join(emergency_reasons))
            col_a, col_b = st.columns(2)
            with col_a:
                st.link_button("í˜„ì§€ 119 ì—°ê²°", "tel:119")
            with col_b:
                st.link_button("í•œêµ­ ê¸´ê¸‰ ì§€ì›(ì¬ì™¸êµ­ë¯¼)", "tel:+82232100404")
            st.caption("ì°¸ê³ : í•´ì™¸ì—ì„œ í•œêµ­ 119 ì§ì ‘ ì—°ê²°ì€ ë¶ˆê°€í•˜ë©°, ì¬ì™¸êµ­ë¯¼ ê¸´ê¸‰ì „í™”ë¡œ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.subheader("ì¡°ì–¸")
            st.write(advice)
            
            if findings:
                st.write("ì´ë¯¸ì§€ ì°¸ê³ : " + ", ".join(findings))
            
            if otc:
                st.subheader("ê¶Œì¥ OTC")
                st.write(", ".join(otc))
                
                # OTC ì´ë¯¸ì§€ í‘œì‹œ
                otc_images = map_otc_to_images(otc)
                if otc_images:
                    st.caption("ëŒ€í‘œ ì´ë¯¸ì§€")
                    cols = st.columns(min(4, len(otc_images)))
                    for i, img in enumerate(otc_images):
                        with cols[i % len(cols)]:
                            st.write(img)
                
                if traveler:
                    brands = map_otc_to_brands(otc)
                    if brands:
                        st.caption("êµ¬ë§¤ ì‹œ ì°¸ê³ (ì„±ë¶„/ì¹´í…Œê³ ë¦¬):")
                        for b in brands:
                            st.write(f"- {b}")
                    
                    jp_phrase = build_jp_phrase(symptoms, otc)
                    st.subheader("ì•½êµ­ì—ì„œ ë³´ì—¬ì¤„ ì¼ë³¸ì–´ ë¬¸ì¥")
                    st.code(jp_phrase)
            
            # ë³‘ì› ì •ë³´ í‘œì‹œ
            if nearby_hospitals:
                st.subheader("ê·¼ì²˜ ë³‘ì›")
                for h in nearby_hospitals[:5]:
                    name = h.get('name', 'Unknown')
                    address = h.get('address', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')
                    lat = h.get('lat')
                    lon = h.get('lon')
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"- **{name}**")
                        st.write(f"  ğŸ“ {address}")
                    with col2:
                        if lat and lon:
                            map_link = build_google_maps_link(lat, lon, name)
                            if map_link:
                                st.link_button("ğŸ—ºï¸ ì§€ë„", map_link)
            
            # ì•½êµ­ ì •ë³´ í‘œì‹œ
            if nearby_pharmacies:
                st.subheader("ê·¼ì²˜ ì•½êµ­")
                for p in nearby_pharmacies[:5]:
                    name = p.get('name', 'Unknown')
                    address = p.get('address', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')
                    lat = p.get('lat')
                    lon = p.get('lon')
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"- **{name}**")
                        st.write(f"  ğŸ“ {address}")
                    with col2:
                        if lat and lon:
                            map_link = build_google_maps_link(lat, lon, name)
                            if map_link:
                                st.link_button("ğŸ—ºï¸ ì§€ë„", map_link)
            
            if evidence_titles:
                st.subheader("ê·¼ê±° ë¬¸ì„œ")
                for t in evidence_titles:
                    st.write(f"- {t}")
            
            # ì˜ì•½í’ˆ ê²€ìƒ‰ ì„¹ì…˜
            if otc:
                st.subheader("ì¼ë³¸ ì˜ì•½í’ˆ ì •ë³´ ê²€ìƒ‰")
                drug_keywords = []
                for o in otc:
                    if "í•´ì—´" in o or "acet" in o.lower():
                        drug_keywords.append("acetaminophen")
                    elif "ì§€ì‚¬" in o:
                        drug_keywords.append("antidiarrheal")
                    elif "ì œì‚°" in o or "ìœ„ì‚°" in o:
                        drug_keywords.append("antacid")
                    elif "ì§„í†µ" in o:
                        drug_keywords.append("analgesic")
                    elif "í•­íˆìŠ¤íƒ€ë¯¼" in o:
                        drug_keywords.append("antihistamine")
                
                if drug_keywords:
                    with st.spinner("ì¼ë³¸ ì˜ì•½í’ˆ ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘..."):
                        for keyword in drug_keywords[:2]:  # ìµœëŒ€ 2ê°œ í‚¤ì›Œë“œë§Œ ê²€ìƒ‰
                            try:
                                drug_results = radar_search(keyword, limit=3)
                                if drug_results:
                                    st.write(f"**{keyword} ê´€ë ¨ ì˜ì•½í’ˆ:**")
                                    for drug in drug_results:
                                        with st.expander(f"ğŸ’Š {drug.get('brand', 'Unknown')}"):
                                            if drug.get('company'):
                                                st.write(f"**ì œì¡°ì‚¬:** {drug['company']}")
                                            if drug.get('active_ingredient'):
                                                st.write(f"**ì£¼ì„±ë¶„:** {drug['active_ingredient']}")
                                            if drug.get('dosage_form'):
                                                st.write(f"**ì œí˜•:** {drug['dosage_form']}")
                                            if drug.get('url'):
                                                st.link_button("ìƒì„¸ ì •ë³´ ë³´ê¸°", drug['url'])
                            except Exception as e:
                                st.write(f"ì˜ì•½í’ˆ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {keyword}")
                                continue
            
            st.caption("ì¼ë³¸ í˜„ì§€ ë“œëŸ­ìŠ¤í† ì–´/ì•½êµ­(Matsumoto Kiyoshi, Welcia ë“±)ì—ì„œ êµ¬ë§¤ ê°€ëŠ¥")
        
        # ë¡œê¹… ì™„ë£Œ
        processing_time = time.time() - start_time
        
        # ì‘ë‹µ í’ˆì§ˆ í‰ê°€
        advice_quality = "good" if rag_confidence > 0.5 and len(rag_results) > 0 else "poor"
        
        # ìœ„ì¹˜ ì •ë³´
        location_coords = None
        if loc and 'latitude' in loc and 'longitude' in loc:
            location_coords = (loc['latitude'], loc['longitude'])
        
        # ë¡œê·¸ ê¸°ë¡
        try:
            log_id = symptom_logger.log_symptom(
                user_input=symptoms,
                image_uploaded=image_uploaded,
                rag_results=rag_results,
                advice_generated=bool(advice),
                advice_quality=advice_quality,
                hospital_found=len(nearby_hospitals) > 0,
                pharmacy_found=len(nearby_pharmacies) > 0,
                location=location_coords,
                processing_time=processing_time,
                session_id=session_id
            )
            st.write(f"ğŸ” ë””ë²„ê¹…: ë¡œê·¸ ID = {log_id}")
        except Exception as e:
            st.write(f"ğŸ” ë””ë²„ê¹…: ë¡œê¹… ì˜¤ë¥˜ = {str(e)}")
        
        # ì²˜ë¦¬ ì‹œê°„ í‘œì‹œ
        st.write(f"ğŸ” ë””ë²„ê¹…: ì²˜ë¦¬ ì‹œê°„ = {processing_time:.2f}ì´ˆ")
