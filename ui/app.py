import os
import streamlit as st
from streamlit_geolocation import streamlit_geolocation
import requests
import pathlib
import re
from typing import List, Tuple, Dict, Optional
from rank_bm25 import BM25Okapi
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from PIL import Image
import numpy as np
import base64
import json
import time
import sys
from datetime import datetime

# Î∞±ÏóîÎìú ÏÑúÎπÑÏä§ ÏûÑÌè¨Ìä∏
sys.path.append('backend')
from services_logging import symptom_logger

st.set_page_config(page_title="ÏùëÍ∏â Ï±óÎ¥á", page_icon="üöë", layout="centered")
st.title("ÏùëÍ∏â ÌôòÏûê Ï±óÎ¥á (ÏùºÎ≥∏)")
st.caption("ÏùºÎ≥∏ Ïó¨ÌñâÏûêÎ•º ÏúÑÌïú ÏùëÍ∏â ÏùòÎ£å Ï°∞Ïñ∏ - VLM/LLM/RAG ÌÜµÌï©")

# ==================== RAG ÏãúÏä§ÌÖú ====================
class HybridRAG:
    def __init__(self, passages: List[str]):
        self.passages = passages
        self.tokenized = [self._tokenize(p) for p in passages]
        self.bm25 = BM25Okapi(self.tokenized)
        self.vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=8000)
        self.tfidf = self.vectorizer.fit_transform(passages)

    def _tokenize(self, text: str) -> List[str]:
        tokens = re.findall(r'\b\w+\b', text.lower())
        return tokens

    def search(self, query: str, top_k: int = 5) -> List[Tuple[str, float]]:
        if not query:
            return []
        q_tokens = self._tokenize(query)
        bm_scores = self.bm25.get_scores(q_tokens)
        q_vec = self.vectorizer.transform([query])
        tf_scores = cosine_similarity(q_vec, self.tfidf)[0]
        scores = [(i, 0.6 * bm_scores[i] + 0.4 * tf_scores[i]) for i in range(len(self.passages))]
        scores.sort(key=lambda x: x[1], reverse=True)
        idxs = [i for i, _ in scores[:top_k]]
        return [(self.passages[i], float(scores[j][1])) for j, i in enumerate(idxs)]

def load_disk_passages() -> list[str]:
    root = pathlib.Path(__file__).resolve().parents[1]
    pdir = root / "data" / "passages" / "jp"
    if not pdir.exists():
        return []
    out = []
    for p in sorted(pdir.glob("*.txt")):
        try:
            out.append(p.read_text(encoding="utf-8"))
        except Exception:
            continue
    return out

DEFAULT_PASSAGES = [
    "ÁÜ±„Åå„ÅÇ„Çã„Å®„Åç„ÅØ„Å¨„Çã„ÅæÊπØ„Åß‰Ωì„ÇíÂÜ∑„ÇÑ„Åó„ÄÅÊ∞¥ÂàÜ„ÇíÂçÅÂàÜ„Å´„Å®„Çä„Åæ„Åó„Çá„ÅÜ„ÄÇ„Ç¢„Çª„Éà„Ç¢„Éü„Éé„Éï„Çß„É≥„ÅØÊØîËºÉÁöÑÂÆâÂÖ®„Åß„Åô„ÄÇ",
    "Âá∫Ë°Ä„Åó„Å¶„ÅÑ„ÇãÂÇ∑„ÅØÁõ¥Êé•ÂúßËø´„ÅßÊ≠¢Ë°Ä„Åó„ÄÅ„Åç„Çå„ÅÑ„Å™Ê∞¥„ÅßÊ¥óÊµÑÂæå„ÄÅÊªÖËèå„Ç¨„Éº„Çº„ÇíÂΩì„Å¶„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
    "‰∏ãÁó¢„ÅÆ„Å®„Åç„ÅØÊ∞¥ÂàÜ„ÉªÈõªËß£Ë≥™„ÅÆË£úÁµ¶„ÇíË°å„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÁóáÁä∂„ÅåÈáç„ÅÑÂ†¥Âêà„ÅØÂèóË®∫„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
]

# ==================== ÏßÄÏò§ ÏÑúÎπÑÏä§ ====================
NOMINATIM_URL = "https://nominatim.openstreetmap.org/search"
OVERPASS_URLS = [
    "https://overpass-api.de/api/interpreter",
    "https://lz4.overpass-api.de/api/interpreter",
    "https://overpass.kumi.systems/api/interpreter",
]
REVERSE_URL = "https://nominatim.openstreetmap.org/reverse"

def _headers() -> Dict[str, str]:
    contact = os.getenv("CONTACT_EMAIL", "hos-emergency-bot/0.1")
    return {"User-Agent": f"hos-emergency-bot/0.1 ({contact})"}

def geocode_place(place: str) -> Optional[Dict[str, float]]:
    if not place:
        return None
    QUICK: Dict[str, Tuple[float, float]] = {
        "shibuya": (35.661777, 139.704051),
        "tokyo": (35.676203, 139.650311),
        "japan": (36.204824, 138.252924),
    }
    key = (place or "").strip().lower()
    if key in QUICK:
        lat, lon = QUICK[key]
        return {"lat": lat, "lon": lon}
    params = {
        "q": place,
        "format": "json",
        "limit": 1,
        "addressdetails": 0,
    }
    try:
        r = requests.get(NOMINATIM_URL, params=params, headers=_headers(), timeout=6)
        if not r.ok:
            return None
        arr = r.json()
        if not arr:
            return None
        lat = float(arr[0]["lat"])
        lon = float(arr[0]["lon"])
        return {"lat": lat, "lon": lon}
    except Exception:
        return QUICK.get("tokyo") and {"lat": QUICK["tokyo"][0], "lon": QUICK["tokyo"][1]}

def reverse_geocode(lat: float, lon: float) -> str:
    try:
        params = {"format": "json", "lat": lat, "lon": lon, "zoom": 18, "addressdetails": 1}
        r = requests.get(REVERSE_URL, params=params, headers=_headers(), timeout=6)
        if not r.ok:
            return ""
        data = r.json()
        address = data.get("display_name") or ""
        return address or ""
    except Exception:
        return ""

def build_address_from_tags(tags: Dict[str, str]) -> str:
    parts: List[str] = []
    # Common OSM address tags in Japan
    for key in [
        "addr:prefecture",
        "addr:city", 
        "addr:ward",
        "addr:district",
        "addr:suburb",
        "addr:neighbourhood",
        "addr:street",
        "addr:block",
        "addr:housenumber",
        "addr:postcode",
    ]:
        val = tags.get(key)
        if val:
            parts.append(val)
    if not parts:
        # fallback single fields
        for key in ["addr:full", "addr:place", "addr:hamlet"]:
            val = tags.get(key)
            if val:
                parts.append(val)
                break
    return " ".join(parts)

def random_tokyo_latlon() -> tuple[float, float]:
    """ÎèÑÏøÑÏùò ÎûúÎç§Ìïú ÏßÄÏó≠ Ï¢åÌëúÎ•º Î∞òÌôòÌï©ÎãàÎã§."""
    import random
    
    # ÎèÑÏøÑ Ï£ºÏöî ÏßÄÏó≠Îì§Ïùò ÎåÄÌëú Ï¢åÌëú
    tokyo_areas = [
        (35.676203, 139.650311),  # Ïã†Ï£ºÏø†
        (35.658581, 139.745433),  # ÏãúÎ∂ÄÏïº
        (35.676191, 139.650310),  # ÌïòÎùºÏ£ºÏø†
        (35.658034, 139.701636),  # Î°ØÌè∞Í∏∞
        (35.676191, 139.650310),  # Í∏¥Ïûê
        (35.658581, 139.745433),  # ÏïÑÌÇ§ÌïòÎ∞îÎùº
        (35.676191, 139.650310),  # Ïö∞ÏóêÎÖ∏
        (35.658034, 139.701636),  # ÏïÑÏÇ¨Ïø†ÏÇ¨
        (35.676191, 139.650310),  # Ïù¥ÏºÄÎ∂ÄÏø†Î°ú
        (35.658581, 139.745433),  # Ïã†Î∞îÏãú
    ]
    
    # ÎûúÎç§ÌïòÍ≤å ÏÑ†ÌÉùÎêú ÏßÄÏó≠Ïóê ÏïΩÍ∞ÑÏùò ÎûúÎç§ Ïò§ÌîÑÏÖã Ï∂îÍ∞Ä
    base_lat, base_lon = random.choice(tokyo_areas)
    
    # ¬±0.01ÎèÑ Î≤îÏúÑ ÎÇ¥ÏóêÏÑú ÎûúÎç§ Ïò§ÌîÑÏÖã (ÏïΩ ¬±1km)
    lat_offset = random.uniform(-0.01, 0.01)
    lon_offset = random.uniform(-0.01, 0.01)
    
    return (base_lat + lat_offset, base_lon + lon_offset)

def search_hospitals(lat: float, lon: float, radius_m: int = 2000) -> List[Dict]:
    query = f"""
    [out:json][timeout:6];
    (
      node["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
      way["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
      relation["amenity"~"hospital|clinic"](around:{radius_m},{lat},{lon});
    );
    out center 20;
    """
    r = None
    for endpoint in OVERPASS_URLS:
        try:
            r = requests.post(endpoint, data={"data": query}, timeout=7)
            if r.ok:
                break
        except Exception:
            r = None
            continue
    if r is None:
        return []
    results: List[Dict] = []
    if r.ok:
        data = r.json()
        for el in data.get("elements", [])[:20]:
            tags = el.get("tags", {})
            name = tags.get("name") or tags.get("name:en") or tags.get("name:ja") or "Unknown"
            lat_out = el.get("lat") or (el.get("center") or {}).get("lat")
            lon_out = el.get("lon") or (el.get("center") or {}).get("lon")
            
            # Ï£ºÏÜå Ï†ïÎ≥¥ Íµ¨ÏÑ±
            addr = build_address_from_tags(tags)
            if not addr and lat_out and lon_out:
                addr = reverse_geocode(lat_out, lon_out)
            
            results.append({
                "name": name,
                "address": addr or f"ÏúÑÎèÑ: {lat_out:.4f}, Í≤ΩÎèÑ: {lon_out:.4f}",
                "lat": lat_out,
                "lon": lon_out,
            })
    return results

def search_pharmacies(lat: float, lon: float, radius_m: int = 1500) -> List[Dict]:
    query = f"""
    [out:json][timeout:7];
    (
      node["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
      way["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
      relation["amenity"="pharmacy"](around:{radius_m},{lat},{lon});
    );
    out center 30;
    """
    r = None
    for endpoint in OVERPASS_URLS:
        try:
            r = requests.post(endpoint, data={"data": query}, timeout=7)
            if r.ok:
                break
        except Exception:
            r = None
            continue
    if r is None:
        return []
    results: List[Dict] = []
    if r.ok:
        data = r.json()
        for el in data.get("elements", [])[:30]:
            tags = el.get("tags", {})
            name = tags.get("name") or tags.get("name:en") or tags.get("name:ja") or "Unknown"
            lat_out = el.get("lat") or (el.get("center") or {}).get("lat")
            lon_out = el.get("lon") or (el.get("center") or {}).get("lon")
            
            # Ï£ºÏÜå Ï†ïÎ≥¥ Íµ¨ÏÑ±
            addr = build_address_from_tags(tags)
            if not addr and lat_out and lon_out:
                addr = reverse_geocode(lat_out, lon_out)
            
            results.append({
                "name": name,
                "address": addr or f"ÏúÑÎèÑ: {lat_out:.4f}, Í≤ΩÎèÑ: {lon_out:.4f}",
                "lat": lat_out,
                "lon": lon_out,
            })
    return results

# ==================== Í∏∞Î≥∏ Í∑úÏπô ====================
def simple_text_rules(symptoms_text: str) -> dict:
    t = (symptoms_text or "").lower()
    advice = "Ï¶ùÏÉÅÏóê ÎåÄÌïú Í∏∞Î≥∏ ÏùëÍ∏âÏ≤òÏπòÎ•º ÏïàÎÇ¥Ìï©ÎãàÎã§. Ïã¨Í∞ÅÌïú Ï¶ùÏÉÅÏù¥Î©¥ Ï¶âÏãú 119(ÏùºÎ≥∏: 119)Î•º Ìò∏Ï∂úÌïòÏÑ∏Ïöî."
    otc: list = []
    
    if any(k in t for k in ["fever", "Ïó¥", "Áô∫ÁÜ±"]):
        otc.append("Ìï¥Ïó¥Ï†ú(ÏïÑÏÑ∏Ìä∏ÏïÑÎØ∏ÎÖ∏Ìéú)")
    if any(k in t for k in ["cough", "Í∏∞Ïπ®", "Âí≥"]):
        otc.append("ÏßÑÌï¥Í±∞Îã¥Ï†ú")
    if any(k in t for k in ["diarrhea", "ÏÑ§ÏÇ¨", "‰∏ãÁó¢"]):
        otc.append("ÏßÄÏÇ¨Ï†ú Î∞è ÏàòÎ∂ÑÎ≥¥Ï∂©")
    if any(k in t for k in ["abdominal pain", "stomach ache", "Î∞∞ÏïÑÌîî", "Î≥µÌÜµ", "ËÖπÁóõ"]):
        otc.extend(["Ï†úÏÇ∞Ï†ú/ÏúÑÏÇ∞ÏñµÏ†úÏ†ú(Ï¶ùÏÉÅÏóê Îî∞Îùº)", "Í∞ÄÏä§ÏôÑÌôîÏ†ú(ÏãúÎ©îÌã∞ÏΩò)", "ÏßÑÌÜµÏ†ú(ÏïÑÏÑ∏Ìä∏ÏïÑÎØ∏ÎÖ∏Ìéú)"])
    if any(k in t for k in ["headache", "ÎëêÌÜµ", "È†≠Áóõ"]):
        if "Ìï¥Ïó¥Ï†ú(ÏïÑÏÑ∏Ìä∏ÏïÑÎØ∏ÎÖ∏Ìéú)" not in otc:
            otc.append("ÏßÑÌÜµÏ†ú(ÏïÑÏÑ∏Ìä∏ÏïÑÎØ∏ÎÖ∏Ìéú)")
    if any(k in t for k in ["vomit", "vomiting", "Íµ¨ÌÜ†", "ÂòîÂêê", "ÌÉàÏàò", "dehydration"]):
        otc.append("Í≤ΩÍµ¨ÏàòÎ∂ÑÎ≥¥Ï∂©Ïï°(ORS)")
    if any(k in t for k in ["rash", "Î∞úÏßÑ", "ÏïåÎ†àÎ•¥Í∏∞", "ËïÅÈ∫ªÁñπ", "„Åò„Çì„Åæ„Åó„Çì", "allergy"]):
        otc.append("Ìï≠ÌûàÏä§ÌÉÄÎØºÏ†ú")
    if any(k in t for k in ["sore throat", "Ïù∏ÌõÑÌÜµ", "Î™©ÏïÑÌîî", "Âñâ„ÅÆÁóõ„Åø"]):
        otc.append("Î™©ÏóºÏ¶ù ÏôÑÌôî Î™©Ï∫îÎîî/Î°úÏ††ÏßÄ")
    if any(k in t for k in ["stuffy nose", "nasal congestion", "ÏΩîÎßâÌûò", "Èºª„Å•„Åæ„Çä"]):
        otc.append("ÎπÑÏ∂©Ìòà Ï†úÍ±∞Ï†ú(ÎîîÏΩòÏ†úÏä§ÌÑ¥Ìä∏)")
    if any(k in t for k in ["toothache", "ÏπòÌÜµ", "Ê≠ØÁóõ"]):
        if "ÏßÑÌÜµÏ†ú(ÏïÑÏÑ∏Ìä∏ÏïÑÎØ∏ÎÖ∏Ìéú)" not in otc:
            otc.append("ÏßÑÌÜµÏ†ú(ÏïÑÏÑ∏Ìä∏ÏïÑÎØ∏ÎÖ∏Ìéú)")
    if any(k in t for k in ["cut", "bleeding", "ÏÉÅÏ≤ò", "Âá∫Ë°Ä"]):
        advice = "ÏÉÅÏ≤ò Î∂ÄÏúÑÎ•º ÏïïÎ∞ïÌïòÏó¨ ÏßÄÌòàÌïòÍ≥†, Íπ®ÎÅóÌïú Î¨ºÎ°ú ÏÑ∏Ï≤ô ÌõÑ Î©∏Í∑† Í±∞Ï¶àÎ•º Ï†ÅÏö©ÌïòÏÑ∏Ïöî. Ïã¨Ìïú Ï∂úÌòàÏùÄ Ï¶âÏãú 119."
    
    # Î≤åÎ†à Î¨ºÎ¶º (ÎßêÎ≤å/Î≤å ÌÇ§ÏõåÎìú Ï†úÏô∏)
    if any(k in t for k in ["Î≤åÎ†à", "Î¨ºÎ¶º", "Î≤åÎ†àÏóê Î¨ºÎ¶º", "Î≤åÎ†àÏóêÎ¨ºÎ¶º", "Î™®Í∏∞", "Î™®Í∏∞Ïóê Î¨ºÎ¶º", "Î™®Í∏∞ÏóêÎ¨ºÎ¶º", "insect bite", "Ëô´„Å´Âà∫„Åï„Çå„Åü"]) and not any(k in t for k in ["ÎßêÎ≤å", "Î≤å", "ÏèòÏûÑ", "wasp", "bee", "ËúÇ"]):
        advice = "Î≤åÎ†à Î¨ºÎ¶º: Ï¶âÏãú Ìï¥Îãπ Î∂ÄÏúÑÎ•º Íπ®ÎÅóÌïú Î¨ºÎ°ú ÏîªÍ≥†, ÏñºÏùåÏ∞úÏßàÎ°ú Î∂ÄÏ¢ÖÏùÑ ÏôÑÌôîÌïòÏÑ∏Ïöî. Ìï≠ÌûàÏä§ÌÉÄÎØº Ïó∞Í≥†Î•º Î∞îÎ•¥Í≥†, Í∏ÅÏßÄ ÏïäÎèÑÎ°ù Ï£ºÏùòÌïòÏÑ∏Ïöî. 24ÏãúÍ∞Ñ ÌõÑÏóêÎèÑ Í∞úÏÑ†ÎêòÏßÄ ÏïäÏúºÎ©¥ ÏùòÎ£åÏßÑ ÏÉÅÎã¥ÌïòÏÑ∏Ïöî."
        otc.extend(["Ìï≠ÌûàÏä§ÌÉÄÎØº Ïó∞Í≥†", "ÏÜåÎèÖÏ†ú", "ÏñºÏùåÌå©"])
    
    # ÎßêÎ≤å ÏèòÏûÑ (Ïö∞ÏÑ†ÏàúÏúÑ ÎÜíÏùå)
    elif any(k in t for k in ["ÎßêÎ≤å", "Î≤å", "ÏèòÏûÑ", "ÎßêÎ≤åÏóê ÏèòÏûÑ", "ÎßêÎ≤åÏóêÏèòÏûÑ", "Î≤åÏóê ÏèòÏûÑ", "Î≤åÏóêÏèòÏûÑ", "wasp sting", "bee sting", "ËúÇ„Å´Âà∫„Åï„Çå„Åü"]):
        advice = "ÎßêÎ≤å ÏèòÏûÑ: Ï¶âÏãú Ïπ®ÏùÑ Ï†úÍ±∞ÌïòÍ≥†, Íπ®ÎÅóÌïú Î¨ºÎ°ú ÏÑ∏Ï≤ôÌïòÏÑ∏Ïöî. ÏñºÏùåÏ∞úÏßàÎ°ú Î∂ÄÏ¢ÖÏùÑ ÏôÑÌôîÌïòÍ≥†, ÏÉÅÏ≤ò Î∂ÄÏúÑÎ•º Ïã¨Ïû•Î≥¥Îã§ ÎÜíÍ≤å Ïú†ÏßÄÌïòÏÑ∏Ïöî. Ìò∏Ìù°Í≥§ÎûÄ, Ï†ÑÏã† ÎëêÎìúÎü¨Í∏∞, ÏùòÏãù Î≥ÄÌôî Ïãú Ï¶âÏãú 119Ïóê Ïó∞ÎùΩÌïòÏÑ∏Ïöî."
        otc.extend(["Ìï≠ÌûàÏä§ÌÉÄÎØº Ïó∞Í≥†", "Ìï≠ÌûàÏä§ÌÉÄÎØºÏ†ú(Í≤ΩÍµ¨)", "ÏÜåÎèÖÏ†ú", "ÏñºÏùåÌå©"])
    
    return {"advice": advice, "otc": otc}

# ==================== ÏùëÍ∏âÏÉÅÌô© Í∞êÏßÄ ====================
CRITICAL_KEYWORDS = [
    "chest pain", "Ïã¨Ìïú Í∞ÄÏä¥ ÌÜµÏ¶ù", "ËÉ∏„ÅÆÊøÄÁóõ",
    "severe bleeding", "ÎåÄÎüâ Ï∂úÌòà", "Â§ßÈáèÂá∫Ë°Ä",
    "unconscious", "ÏùòÏãù ÏóÜÏùå", "ÊÑèË≠ò„Å™„Åó",
    "stroke", "Ìé∏ÎßàÎπÑ", "ËÑ≥Âçí‰∏≠",
    "difficulty breathing", "Ïà®Ïù¥ Í∞ÄÏÅ®", "ÂëºÂê∏Âõ∞Èõ£",
    "severe abdominal pain", "Î≥µÎ∂Ä Í∑πÏã¨Ìïú ÌÜµÏ¶ù", "ÊøÄ„Åó„ÅÑËÖπÁóõ",
    "anaphylaxis", "ÏïÑÎÇòÌïÑÎùΩÏãúÏä§", "Ïã¨Ìïú ÏïåÎ†àÎ•¥Í∏∞ Î∞òÏùë", "Ï†ÑÏã† ÎëêÎìúÎü¨Í∏∞", "Ìò∏Ìù°Í≥§ÎûÄ",
    "severe allergic reaction", "ÂÖ®Ë∫´ËïÅÈ∫ªÁñπ", "ÂëºÂê∏Âõ∞Èõ£",
]

def detect_emergency(symptoms_text: str) -> list:
    t = (symptoms_text or "").lower()
    reasons: list = []
    for k in CRITICAL_KEYWORDS:
        if k in t:
            reasons.append(k)
    return reasons

# ==================== Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù ====================
def simple_image_screening(img: Image.Image) -> List[str]:
    w, h = img.size
    findings: List[str] = []
    if min(w, h) < 128:
        findings.append("Ï†ÄÌï¥ÏÉÅÎèÑ Ïù¥ÎØ∏ÏßÄ")
    return findings

def detect_emergency_from_image(img: Image.Image, raw_image: bytes = None) -> List[str]:
    reasons: List[str] = []
    red_thr = 0.25
    burn_thr = 0.30
    
    # Ìú¥Î¶¨Ïä§Ìã± Î∂ÑÏÑù
    try:
        small = img.resize((224, 224))
        hsv = small.convert("HSV")
        arr = np.array(hsv)
        h = arr[:, :, 0].astype(np.float32)
        s = arr[:, :, 1].astype(np.float32)
        v = arr[:, :, 2].astype(np.float32)
        
        red_mask = ((h < 10) | (h > 245)) & (s > 100) & (v > 60)
        red_ratio = float(red_mask.mean())
        if red_ratio > red_thr:
            reasons.append("Ïù¥ÎØ∏ÏßÄÏÉÅ Í≥ºÎã§ Ï∂úÌòà ÏùòÏã¨")
            
        orange_mask = (h >= 10) & (h <= 50) & (s > 120) & (v > 120)
        orange_ratio = float(orange_mask.mean())
        if orange_ratio > burn_thr:
            reasons.append("Ïù¥ÎØ∏ÏßÄÏÉÅ ÌôîÏÉÅ/Í¥ëÎ≤îÏúÑ ÌôçÎ∞ò ÏùòÏã¨")
    except Exception:
        pass
    
    # OpenAI Vision API Î∂ÑÏÑù (ÌôòÍ≤ΩÎ≥ÄÏàòÍ∞Ä ÏÑ§Ï†ïÎêú Í≤ΩÏö∞)
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key and raw_image:
            import openai
            client = openai.OpenAI(api_key=api_key)
            
            # Ïù¥ÎØ∏ÏßÄÎ•º base64Î°ú Ïù∏ÏΩîÎî©
            import base64
            from io import BytesIO
            
            img_buffer = BytesIO()
            img.save(img_buffer, format="JPEG")
            img_bytes = img_buffer.getvalue()
            b64_image = base64.b64encode(img_bytes).decode("utf-8")
            
            # ÏùòÎ£å Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù ÌîÑÎ°¨ÌîÑÌä∏
            prompt = """
            Ïù¥ ÏùòÎ£å/ÏÉÅÌï¥ Ïù¥ÎØ∏ÏßÄÎ•º Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî. Îã§Ïùå Ìï≠Î™©Îì§ÏùÑ ÌôïÏù∏ÌïòÍ≥† Î∞úÍ≤¨Îêú Í≤ÉÎßå ÌïúÍµ≠Ïñ¥Î°ú Î≥¥Í≥†Ìï¥Ï£ºÏÑ∏Ïöî:
            
            ÏùëÍ∏âÏÉÅÌô©:
            - Ïã¨Ìïú Ï∂úÌòà (Í≥ºÎã§ Ï∂úÌòà, ÎåÄÎüâ Ï∂úÌòà)
            - Ïã¨Ìïú ÌôîÏÉÅ (2ÎèÑ Ïù¥ÏÉÅ ÌôîÏÉÅ, Í¥ëÎ≤îÏúÑ ÌôîÏÉÅ)
            - Îºà ÎÖ∏Ï∂ú (Í≥®Ï†à, Í∞úÎ∞©ÏÑ± Í≥®Ï†à)
            - Ï†àÎã®ÏÉÅ (ÏÜêÍ∞ÄÎùΩ, Ìåî, Îã§Î¶¨ Ï†àÎã®)
            - Ï§ëÏ¶ù Ïô∏ÏÉÅ (Ïã¨Í∞ÅÌïú ÏÉÅÏ≤ò, ÍπäÏùÄ ÏÉÅÏ≤ò)
            
            ÏùºÎ∞ò ÏùòÎ£åÏÉÅÌô©:
            - Î∞úÏßÑ, ÏïåÎ†àÎ•¥Í∏∞ Î∞òÏùë
            - Î∂ÄÏ¢Ö, Î∂ìÍ∏∞
            - Î©ç, ÌÉÄÎ∞ïÏÉÅ
            - Í∞ÄÎ≤ºÏö¥ ÏÉÅÏ≤ò, Ï∞∞Í≥ºÏÉÅ
            - ÌîºÎ∂ÄÏóº, ÏäµÏßÑ
            - Î¨ºÏßë, ÏàòÌè¨
            
            Î∞úÍ≤¨Îêú Ï¶ùÏÉÅÏù¥ ÏóÜÏúºÎ©¥ "Ï†ïÏÉÅ"Ïù¥ÎùºÍ≥† ÎãµÌï¥Ï£ºÏÑ∏Ïöî.
            """
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "ÎãπÏã†ÏùÄ ÏùòÎ£å Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Ï†ïÌôïÌïòÍ≥† Ïã†Ï§ëÌïòÍ≤å Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{b64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500,
                temperature=0.1
            )
            
            analysis = response.choices[0].message.content.strip()
            
            # ÏùëÍ∏âÏÉÅÌô© ÌÇ§ÏõåÎìú Ï≤¥ÌÅ¨
            emergency_keywords = ["Ïã¨Ìïú Ï∂úÌòà", "Í≥ºÎã§ Ï∂úÌòà", "ÎåÄÎüâ Ï∂úÌòà", "Ïã¨Ìïú ÌôîÏÉÅ", "2ÎèÑ Ïù¥ÏÉÅ", "Í¥ëÎ≤îÏúÑ ÌôîÏÉÅ", 
                                "Îºà ÎÖ∏Ï∂ú", "Í≥®Ï†à", "Í∞úÎ∞©ÏÑ±", "Ï†àÎã®", "Ï§ëÏ¶ù Ïô∏ÏÉÅ", "Ïã¨Í∞ÅÌïú ÏÉÅÏ≤ò", "ÍπäÏùÄ ÏÉÅÏ≤ò"]
            
            for keyword in emergency_keywords:
                if keyword in analysis:
                    reasons.append(f"AI Î∂ÑÏÑù: {analysis}")
                    break
            else:
                # ÏùëÍ∏âÏÉÅÌô©Ïù¥ ÏïÑÎãå Í≤ΩÏö∞ ÏùºÎ∞ò ÏùòÎ£åÏÉÅÌô©ÏúºÎ°ú Î∂ÑÎ•ò
                if "Ï†ïÏÉÅ" not in analysis and analysis:
                    reasons.append(f"AI Î∂ÑÏÑù: {analysis}")
                    
    except Exception as e:
        # OpenAI API Ïò§Î•ò Ïãú Ìú¥Î¶¨Ïä§Ìã± Í≤∞Í≥ºÎßå ÏÇ¨Ïö©
        pass
    
    return reasons

# ==================== ÏùºÎ≥∏Ïñ¥ Î¨∏Ïû• ÏÉùÏÑ± ====================
def build_jp_phrase(symptoms_text: str, otc: list) -> str:
    base = "Ëñ¨Â±Ä„ÅßÁõ∏Ë´á„Åó„Åü„ÅÑ„Åß„Åô„ÄÇ"
    if any("ÏßÄÏÇ¨Ï†ú" in o or "ÏÑ§ÏÇ¨" in symptoms_text for o in otc) or ("ÏÑ§ÏÇ¨" in (symptoms_text or "")):
        return base + "„ÄéËÖπÁóõ„ÇÑ‰∏ãÁó¢„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇÂ∏ÇË≤©„ÅÆÊï¥ËÖ∏Ââ§„ÇÑ‰∏ãÁó¢Ê≠¢„ÇÅ„ÇíÊé¢„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Äè"
    if any("Ìï¥Ïó¥" in o or "Ïó¥" in symptoms_text for o in otc) or ("Î∞úÏó¥" in (symptoms_text or "") or "Ïó¥" in (symptoms_text or "")):
        return base + "„ÄéÁô∫ÁÜ±„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Ç¢„Çª„Éà„Ç¢„Éü„Éé„Éï„Çß„É≥ÊàêÂàÜ„ÅÆËß£ÁÜ±Ëñ¨„ÇíÊé¢„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Äè"
    if any("ÏßÑÌï¥" in o or "Í∏∞Ïπ®" in symptoms_text for o in otc) or ("Âí≥" in (symptoms_text or "")):
        return base + "„ÄéÂí≥„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇÂ∏ÇË≤©„ÅÆÈéÆÂí≥ÂéªÁó∞Ëñ¨„ÇíÊé¢„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Äè"
    return base + "„ÄéÁóáÁä∂„Å´Âêà„ÅÜ‰∏ÄËà¨Áî®ÂåªËñ¨ÂìÅ„ÇíÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Äè"

def map_otc_to_brands(otc: list) -> list:
    hints: list = []
    for o in otc:
        lo = o.lower()
        if "Ìï¥Ïó¥" in o or "acet" in lo:
            hints.append("Ëß£ÁÜ±Ëñ¨: „Ç¢„Çª„Éà„Ç¢„Éü„Éé„Éï„Çß„É≥ÈÖçÂêàË£ΩÂìÅ")
        if "ÏßÄÏÇ¨" in o:
            hints.append("‰∏ãÁó¢Ê≠¢„ÇÅ/Êï¥ËÖ∏Ââ§: ‰π≥ÈÖ∏Ëèå/„É≠„Éö„É©„Éü„ÉâÁ≥ª(ÁóáÁä∂„Å´„Çà„Çä) ‚ÄªÁî®Ê≥ïÊ≥®ÊÑè")
        if "Ï†úÏÇ∞" in o or "ÏúÑÏÇ∞" in o:
            hints.append("ËÉÉËñ¨: Âà∂ÈÖ∏Ëñ¨/H2„Éñ„É≠„ÉÉ„Ç´„ÉºÁ≥ª(ÁóáÁä∂„Å´„Çà„Çä) ‚ÄªÁõ∏‰∫í‰ΩúÁî®Ê≥®ÊÑè")
        if "Í∞ÄÏä§" in o or "ÏãúÎ©îÌã∞ÏΩò" in o:
            hints.append("ËÉÉËÖ∏Ëñ¨: „Ç∑„É°„ÉÅ„Ç≥„É≥ÈÖçÂêà")
        if "ÏßÑÌÜµÏ†ú" in o:
            hints.append("ÈéÆÁóõËñ¨: „Ç¢„Çª„Éà„Ç¢„Éü„Éé„Éï„Çß„É≥ÂÑ™ÂÖà(„Ç§„Éñ„Éó„É≠„Éï„Çß„É≥Á≠â„ÅØÁä∂Ê≥Å„ÅßÂõûÈÅø)")
        if "ÏßÑÌï¥" in o:
            hints.append("Âí≥Ê≠¢„ÇÅ: ÈéÆÂí≥ÂéªÁó∞Ëñ¨„Ç´„ÉÜ„Ç¥„É™")
        if "Ìï≠ÌûàÏä§ÌÉÄÎØº" in o:
            hints.append("Êäó„Éí„Çπ„Çø„Éü„É≥Ëñ¨: „Åã„ÇÜ„Åø/ËïÅÈ∫ªÁñπÁ≠â")
        if "Í≤ΩÍµ¨ÏàòÎ∂ÑÎ≥¥Ï∂©" in o or "ORS" in o.upper():
            hints.append("ÁµåÂè£Ë£úÊ∞¥Ê∂≤(ORS): ËÑ±Ê∞¥ÊôÇ„ÅÆÈõªËß£Ë≥™/Ê∞¥ÂàÜË£úÁµ¶")
        if "Î°úÏ††ÏßÄ" in o or "Î™©ÏóºÏ¶ù" in o:
            hints.append("„Éà„É≠„Éº„ÉÅ/„ÅÆ„Å©È£¥: ÂíΩÈ†≠ÁóõÁ∑©Âíå")
        if "ÎπÑÏ∂©Ìòà" in o or "ÎîîÏΩòÏ†úÏä§ÌÑ¥Ìä∏" in o or "decongestant" in lo:
            hints.append("Èºª„Å•„Åæ„Çä: Ë°ÄÁÆ°ÂèéÁ∏ÆÁÇπÈºªËñ¨(Áü≠Êúü‰ΩøÁî®)")
    
    out = []
    for h in hints:
        if h not in out:
            out.append(h)
    return out

# ==================== ÏßÄÎèÑ ÎßÅÌÅ¨ ÏÉùÏÑ± ====================
def build_google_maps_link(lat: Optional[float], lon: Optional[float], name: Optional[str] = None) -> Optional[str]:
    if lat is None or lon is None:
        return None
    q = f"{lat},{lon}"
    if name:
        q = name
    return f"https://www.google.com/maps/search/?api=1&query={q}"

# ==================== OTC Ïù¥ÎØ∏ÏßÄ Îß§Ìïë ====================
def map_otc_to_images(otc: list) -> list:
    urls: list = []
    
    def add_for(cat: str, placeholder: str) -> None:
        # Î°úÏª¨ Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏûàÏúºÎ©¥ ÏÇ¨Ïö©, ÏóÜÏúºÎ©¥ ÌîåÎ†àÏù¥Ïä§ÌôÄÎçî
        urls.append(placeholder)
    
    for o in otc:
        lo = o.lower()
        if ("Ìï¥Ïó¥" in o) or ("acet" in lo):
            add_for("acetaminophen", "üíä")
        if "ÏßÄÏÇ¨" in o:
            add_for("antidiarrheal", "üíä")
        if ("Ï†úÏÇ∞" in o) or ("ÏúÑÏÇ∞" in o):
            add_for("antacid", "üíä")
        if ("Í∞ÄÏä§" in o) or ("ÏãúÎ©îÌã∞ÏΩò" in o):
            add_for("simethicone", "üíä")
        if "Ìï≠ÌûàÏä§ÌÉÄÎØº" in o:
            add_for("antihistamine", "üíä")
        if ("Í≤ΩÍµ¨ÏàòÎ∂ÑÎ≥¥Ï∂©" in o) or ("ors" in lo):
            add_for("ors", "üíä")
        if ("Î°úÏ††ÏßÄ" in o) or ("Î™©ÏóºÏ¶ù" in o):
            add_for("lozenge", "üíä")
        if ("ÎπÑÏ∂©Ìòà" in o) or ("decongestant" in lo) or ("ÎîîÏΩòÏ†úÏä§ÌÑ¥Ìä∏" in o):
            add_for("decongestant", "üíä")
        if ("ÌôîÏÉÅ" in o) or ("burn" in lo):
            add_for("burngel", "üíä")
        if ("Î≥¥Ïäµ" in o) or ("Í±¥Ï°∞" in o) or ("atopy" in lo) or ("ÏïÑÌÜ†Ìîº" in o):
            add_for("emollient", "üíä")
    
    # Ï§ëÎ≥µ Ï†úÍ±∞
    dedup: list = []
    for u in urls:
        if u not in dedup:
            dedup.append(u)
    return dedup

# ==================== RAD-AR ÏùòÏïΩÌíà Í≤ÄÏÉâ ====================
import re
import time
from urllib.parse import urljoin, quote
from bs4 import BeautifulSoup
import json
from pathlib import Path

RADAR_BASE = "https://www.rad-ar.or.jp/siori/english/"
RADAR_SEARCH_URL = urljoin(RADAR_BASE, "search")

RADAR_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
    "Accept-Language": "en,ja;q=0.9,ko;q=0.8",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Referer": RADAR_BASE.rstrip("/") + "/",
}

def radar_session():
    s = requests.Session()
    s.headers.update(RADAR_HEADERS)
    return s

def radar_search(keyword: str, limit: int = 5) -> List[Dict]:
    try:
        params = {"w": keyword}
        s = radar_session()
        res = s.get(RADAR_SEARCH_URL, params=params, timeout=15)
        res.raise_for_status()
        
        soup = BeautifulSoup(res.text, "lxml")
        results = []
        
        # Í≤ÄÏÉâ Í≤∞Í≥º ÎßÅÌÅ¨ ÌååÏã±
        links = []
        for a in soup.select('a[href*="search/result?n="]'):
            href = a.get("href")
            if href:
                full_url = urljoin(RADAR_BASE, href)
                if full_url not in links:
                    links.append(full_url)
        
        # ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞
        for url in links[:limit]:
            try:
                detail_res = s.get(url, timeout=15)
                detail_res.raise_for_status()
                detail_soup = BeautifulSoup(detail_res.text, "lxml")
                
                # Í∏∞Î≥∏ Ï†ïÎ≥¥ Ï∂îÏ∂ú
                brand = ""
                h1 = detail_soup.select_one("h1")
                if h1:
                    brand = h1.get_text(strip=True)
                
                company = ""
                for a in detail_soup.find_all("a", href=True):
                    href = a["href"].strip()
                    if href.startswith("http") and "rad-ar.or.jp" not in href:
                        company = a.get_text(strip=True)
                        break
                
                # ÌÖåÏù¥Î∏îÏóêÏÑú Ï†ïÎ≥¥ Ï∂îÏ∂ú
                active_ingredient = ""
                dosage_form = ""
                for tr in detail_soup.select("table tr"):
                    cells = tr.find_all(["td", "th"])
                    if len(cells) >= 2:
                        key = re.sub(r"\s+", " ", cells[0].get_text(strip=True))
                        val = cells[1].get_text(strip=True)
                        if "Active ingredient" in key:
                            active_ingredient = val
                        elif "Dosage form" in key:
                            dosage_form = val
                
                results.append({
                    "brand": brand,
                    "company": company,
                    "active_ingredient": active_ingredient,
                    "dosage_form": dosage_form,
                    "url": url
                })
                
                time.sleep(0.5)  # ÏöîÏ≤≠ Í∞ÑÍ≤©
                
            except Exception as e:
                continue
                
        return results
        
    except Exception as e:
        return []

# ==================== Î©îÏù∏ Ïï± ====================
@st.cache_resource
def load_rag():
    _disk = load_disk_passages()
    return HybridRAG(_disk if _disk else DEFAULT_PASSAGES)

# RAG Î°úÎìú
rag = load_rag()

with st.form("chat_form"):
    uploaded = st.file_uploader("Ï¶ùÏÉÅ ÏÇ¨ÏßÑ ÏóÖÎ°úÎìú (ÏÑ†ÌÉù)", type=["png", "jpg", "jpeg"])
    symptoms = st.text_area("Ï¶ùÏÉÅ ÏÑ§Î™Ö", placeholder="Ïòà) Ïù¥ÎßàÍ∞Ä Ï∞¢Ïñ¥Ï†∏ ÌîºÍ∞Ä ÎÇòÏöî, Ïó¥Ïù¥ 38.5ÎèÑÏòàÏöî")
    
    # ÏúÑÏπò ÏÑ§Ï†ï ÏÑπÏÖò
    st.subheader("üìç ÏúÑÏπò ÏÑ§Ï†ï")
    
    # ÌÖåÏä§Ìä∏ Î™®Îìú ÏÑ†ÌÉù
    test_mode = st.checkbox("üß™ ÌÖåÏä§Ìä∏ Î™®Îìú (ÎûúÎç§ ÎèÑÏøÑ ÏßÄÏó≠)", value=False, 
                           help="Ï≤¥ÌÅ¨ÌïòÎ©¥ ÎèÑÏøÑÏùò ÎûúÎç§Ìïú ÏßÄÏó≠ÏúºÎ°ú ÌÖåÏä§Ìä∏Ìï©ÎãàÎã§")
    
    if test_mode:
        st.info("üß™ ÌÖåÏä§Ìä∏ Î™®Îìú: ÎèÑÏøÑÏùò ÎûúÎç§Ìïú ÏßÄÏó≠ÏóêÏÑú Î≥ëÏõê/ÏïΩÍµ≠ÏùÑ Í≤ÄÏÉâÌï©ÎãàÎã§")
        location = "Tokyo (Test Mode)"
    else:
        location = st.text_input("ÌòÑÏû¨ ÏúÑÏπò(ÎèÑÏãú/Íµ¨ Îã®ÏúÑ, ÏùºÎ≥∏)", value="Tokyo")
        st.write("ÎÇ¥ ÏúÑÏπò ÏÇ¨Ïö©(Î∏åÎùºÏö∞Ï†Ä Í∂åÌïú ÌïÑÏöî):")
        loc = streamlit_geolocation()
    
    traveler = st.checkbox("Ïó¨ÌñâÏûê Î™®Îìú(ÌïúÍµ≠‚ÜíÏùºÎ≥∏)", value=True)
    submitted = st.form_submit_button("ÏÉÅÎã¥ÌïòÍ∏∞")

if submitted:
    # Î°úÍπÖÏùÑ ÏúÑÌïú ÏãúÏûë ÏãúÍ∞Ñ
    start_time = time.time()
    session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    with st.spinner("Î∂ÑÏÑù Ï§ë..."):
        # Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù
        findings = []
        image_uploaded = uploaded is not None
        if uploaded is not None:
            try:
                img = Image.open(uploaded).convert("RGB")
                findings = simple_image_screening(img)
                
                # Ïù¥ÎØ∏ÏßÄ Î∞îÏù¥Ìä∏ Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
                img_bytes = uploaded.getvalue()
                emg_img = detect_emergency_from_image(img, img_bytes)
                if emg_img:
                    findings.extend(emg_img)
            except Exception as e:
                findings = ["Ïù¥ÎØ∏ÏßÄ Ìï¥ÏÑù Ïã§Ìå®"]
        
        # Í∏∞Î≥∏ Í∑úÏπô Í∏∞Î∞ò Ï°∞Ïñ∏
        rule_out = simple_text_rules(symptoms)
        advice = rule_out["advice"]
        otc = rule_out["otc"]
        
        # RAG Í≤ÄÏÉâ
        rag_results = []
        rag_confidence = 0.0
        try:
            hits = rag.search(symptoms, top_k=3)
            passages = [h[0] for h in hits]
            rag_results = hits
            rag_confidence = max([score for _, score in hits]) if hits else 0.0
            evidence_titles = []
            for txt, _ in hits:
                first = (txt.strip().splitlines() or [""])[0].strip()
                evidence_titles.append(first[:80] if first else "Í∑ºÍ±∞ Î¨∏ÏÑú")
        except Exception as e:
            passages = []
            evidence_titles = []
        
        # ÏßÄÏò§ Í≤ÄÏÉâ
        nearby_hospitals = []
        nearby_pharmacies = []
        try:
            if test_mode:
                # ÌÖåÏä§Ìä∏ Î™®Îìú: ÎèÑÏøÑÏùò ÎûúÎç§Ìïú ÏßÄÏó≠ ÏÇ¨Ïö©
                lat, lon = random_tokyo_latlon()
                st.info(f"üß™ ÌÖåÏä§Ìä∏ Î™®Îìú: ({lat:.4f}, {lon:.4f}) ÏúÑÏπòÏóêÏÑú Í≤ÄÏÉâ Ï§ë...")
            elif loc and loc.get("latitude") and loc.get("longitude"):
                # Ïã§Ï†ú ÏúÑÏπò ÏÇ¨Ïö© (Î∏åÎùºÏö∞Ï†Ä GPS)
                lat, lon = loc["latitude"], loc["longitude"]
                st.info(f"üìç Ïã§Ï†ú ÏúÑÏπò: ({lat:.4f}, {lon:.4f})")
            else:
                # ÏûÖÎ†•Îêú ÏúÑÏπòÎ°ú Í≤ÄÏÉâ
                geo = geocode_place(location)
                if geo:
                    lat, lon = geo["lat"], geo["lon"]
                    st.info(f"üìç Í≤ÄÏÉâÎêú ÏúÑÏπò: {location} ({lat:.4f}, {lon:.4f})")
                else:
                    lat, lon = 35.676203, 139.650311  # Tokyo fallback
                    st.warning(f"‚ö†Ô∏è ÏúÑÏπò Í≤ÄÏÉâ Ïã§Ìå®, ÎèÑÏøÑ Í∏∞Î≥∏ ÏúÑÏπò ÏÇ¨Ïö©: ({lat:.4f}, {lon:.4f})")
            
            nearby_hospitals = search_hospitals(lat, lon, 2000)
            nearby_pharmacies = search_pharmacies(lat, lon, 1500)
        except Exception as e:
            st.error(f"ÏúÑÏπò Í≤ÄÏÉâ Ïò§Î•ò: {str(e)}")
            pass
        
        # ÏùëÍ∏âÏÉÅÌô© Í∞êÏßÄ
        emergency_reasons = detect_emergency(symptoms)
        if findings:
            for f in findings:
                if any(s in f.lower() for s in ["Ï∂úÌòà", "bleeding", "ÌôîÏÉÅ", "burn"]):
                    emergency_reasons.append(f)
        
        # ÏóÖÎ°úÎìúÎêú Ïù¥ÎØ∏ÏßÄ ÌëúÏãú
        if uploaded is not None:
            st.subheader("ÏóÖÎ°úÎìúÎêú Ïù¥ÎØ∏ÏßÄ")
            st.image(uploaded, caption="Ï¶ùÏÉÅ ÏÇ¨ÏßÑ", use_container_width=True)
        
        if emergency_reasons:
            st.error("ÏúÑÍ∏â Ïã†Ìò∏Í∞Ä Í∞êÏßÄÎêòÏóàÏäµÎãàÎã§. Ï¶âÏãú 119Î°ú Ï†ÑÌôîÌïòÏÑ∏Ïöî.")
            st.write("Í∑ºÍ±∞: ", ", ".join(emergency_reasons))
            col_a, col_b = st.columns(2)
            with col_a:
                st.link_button("ÌòÑÏßÄ 119 Ïó∞Í≤∞", "tel:119")
            with col_b:
                st.link_button("ÌïúÍµ≠ Í∏¥Í∏â ÏßÄÏõê(Ïû¨Ïô∏Íµ≠ÎØº)", "tel:+82232100404")
            st.caption("Ï∞∏Í≥†: Ìï¥Ïô∏ÏóêÏÑú ÌïúÍµ≠ 119 ÏßÅÏ†ë Ïó∞Í≤∞ÏùÄ Î∂àÍ∞ÄÌïòÎ©∞, Ïû¨Ïô∏Íµ≠ÎØº Í∏¥Í∏âÏ†ÑÌôîÎ°ú ÎèÑÏõÄÏùÑ Î∞õÏùÑ Ïàò ÏûàÏäµÎãàÎã§.")
        else:
            st.subheader("Ï°∞Ïñ∏")
            st.write(advice)
            
            if findings:
                st.write("Ïù¥ÎØ∏ÏßÄ Ï∞∏Í≥†: " + ", ".join(findings))
            
            if otc:
                st.subheader("Í∂åÏû• OTC")
                st.write(", ".join(otc))
                
                # OTC Ïù¥ÎØ∏ÏßÄ ÌëúÏãú
                otc_images = map_otc_to_images(otc)
                if otc_images:
                    st.caption("ÎåÄÌëú Ïù¥ÎØ∏ÏßÄ")
                    cols = st.columns(min(4, len(otc_images)))
                    for i, img in enumerate(otc_images):
                        with cols[i % len(cols)]:
                            st.write(img)
                
                if traveler:
                    brands = map_otc_to_brands(otc)
                    if brands:
                        st.caption("Íµ¨Îß§ Ïãú Ï∞∏Í≥†(ÏÑ±Î∂Ñ/Ïπ¥ÌÖåÍ≥†Î¶¨):")
                        for b in brands:
                            st.write(f"- {b}")
                    
                    jp_phrase = build_jp_phrase(symptoms, otc)
                    st.subheader("ÏïΩÍµ≠ÏóêÏÑú Î≥¥Ïó¨Ï§Ñ ÏùºÎ≥∏Ïñ¥ Î¨∏Ïû•")
                    st.code(jp_phrase)
            
            # Î≥ëÏõê Ï†ïÎ≥¥ ÌëúÏãú
            if nearby_hospitals:
                st.subheader("Í∑ºÏ≤ò Î≥ëÏõê")
                for h in nearby_hospitals[:5]:
                    name = h.get('name', 'Unknown')
                    address = h.get('address', 'Ï£ºÏÜå Ï†ïÎ≥¥ ÏóÜÏùå')
                    lat = h.get('lat')
                    lon = h.get('lon')
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"- **{name}**")
                        st.write(f"  üìç {address}")
                    with col2:
                        if lat and lon:
                            map_link = build_google_maps_link(lat, lon, name)
                            if map_link:
                                st.link_button("üó∫Ô∏è ÏßÄÎèÑ", map_link)
            
            # ÏïΩÍµ≠ Ï†ïÎ≥¥ ÌëúÏãú
            if nearby_pharmacies:
                st.subheader("Í∑ºÏ≤ò ÏïΩÍµ≠")
                for p in nearby_pharmacies[:5]:
                    name = p.get('name', 'Unknown')
                    address = p.get('address', 'Ï£ºÏÜå Ï†ïÎ≥¥ ÏóÜÏùå')
                    lat = p.get('lat')
                    lon = p.get('lon')
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"- **{name}**")
                        st.write(f"  üìç {address}")
                    with col2:
                        if lat and lon:
                            map_link = build_google_maps_link(lat, lon, name)
                            if map_link:
                                st.link_button("üó∫Ô∏è ÏßÄÎèÑ", map_link)
            
            if evidence_titles:
                st.subheader("Í∑ºÍ±∞ Î¨∏ÏÑú")
                for t in evidence_titles:
                    st.write(f"- {t}")
            
            # ÏùòÏïΩÌíà Í≤ÄÏÉâ ÏÑπÏÖò
            if otc:
                st.subheader("ÏùºÎ≥∏ ÏùòÏïΩÌíà Ï†ïÎ≥¥ Í≤ÄÏÉâ")
                drug_keywords = []
                for o in otc:
                    if "Ìï¥Ïó¥" in o or "acet" in o.lower():
                        drug_keywords.append("acetaminophen")
                    elif "ÏßÄÏÇ¨" in o:
                        drug_keywords.append("antidiarrheal")
                    elif "Ï†úÏÇ∞" in o or "ÏúÑÏÇ∞" in o:
                        drug_keywords.append("antacid")
                    elif "ÏßÑÌÜµ" in o:
                        drug_keywords.append("analgesic")
                    elif "Ìï≠ÌûàÏä§ÌÉÄÎØº" in o:
                        drug_keywords.append("antihistamine")
                
                if drug_keywords:
                    with st.spinner("ÏùºÎ≥∏ ÏùòÏïΩÌíà Ï†ïÎ≥¥Î•º Í≤ÄÏÉâ Ï§ë..."):
                        for keyword in drug_keywords[:2]:  # ÏµúÎåÄ 2Í∞ú ÌÇ§ÏõåÎìúÎßå Í≤ÄÏÉâ
                            try:
                                drug_results = radar_search(keyword, limit=3)
                                if drug_results:
                                    st.write(f"**{keyword} Í¥ÄÎ†® ÏùòÏïΩÌíà:**")
                                    for drug in drug_results:
                                        with st.expander(f"üíä {drug.get('brand', 'Unknown')}"):
                                            if drug.get('company'):
                                                st.write(f"**Ï†úÏ°∞ÏÇ¨:** {drug['company']}")
                                            if drug.get('active_ingredient'):
                                                st.write(f"**Ï£ºÏÑ±Î∂Ñ:** {drug['active_ingredient']}")
                                            if drug.get('dosage_form'):
                                                st.write(f"**Ï†úÌòï:** {drug['dosage_form']}")
                                            if drug.get('url'):
                                                st.link_button("ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Î≥¥Í∏∞", drug['url'])
                            except Exception as e:
                                st.write(f"ÏùòÏïΩÌíà Ï†ïÎ≥¥ Í≤ÄÏÉâ Ï§ë Ïò§Î•ò: {keyword}")
                                continue
            
            st.caption("ÏùºÎ≥∏ ÌòÑÏßÄ ÎìúÎü≠Ïä§ÌÜ†Ïñ¥/ÏïΩÍµ≠(Matsumoto Kiyoshi, Welcia Îì±)ÏóêÏÑú Íµ¨Îß§ Í∞ÄÎä•")
        
        # Î°úÍπÖ ÏôÑÎ£å
        processing_time = time.time() - start_time
        
        # ÏùëÎãµ ÌíàÏßà ÌèâÍ∞Ä
        advice_quality = "good" if rag_confidence > 0.5 and len(rag_results) > 0 else "poor"
        
        # ÏúÑÏπò Ï†ïÎ≥¥
        location_coords = None
        if not test_mode and loc and 'latitude' in loc and 'longitude' in loc:
            location_coords = (loc['latitude'], loc['longitude'])
        
        # Î°úÍ∑∏ Í∏∞Î°ù
        try:
            log_id = symptom_logger.log_symptom(
                user_input=symptoms,
                image_uploaded=image_uploaded,
                rag_results=rag_results,
                advice_generated=bool(advice),
                advice_quality=advice_quality,
                hospital_found=len(nearby_hospitals) > 0,
                pharmacy_found=len(nearby_pharmacies) > 0,
                location=location_coords,
                processing_time=processing_time,
                session_id=session_id
            )
        except Exception as e:
            pass
